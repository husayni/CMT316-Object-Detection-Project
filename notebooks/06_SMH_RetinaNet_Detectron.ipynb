{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1746229779108
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['CLEARML_API_ACCESS_KEY'] = os.getenv(\"CLEARML_API_ACCESS_KEY\")\n",
        "os.environ['CLEARML_API_SECRET_KEY'] = os.getenv(\"CLEARML_API_SECRET_KEY\")\n",
        "os.environ[\"CLEARML_WEB_HOST\"]  = \"https://app.clear.ml/\"\n",
        "os.environ[\"CLEARML_API_HOST\"]  = \"https://api.clear.ml\"\n",
        "os.environ[\"CLEARML_FILES_HOST\"] = \"https://files.clear.ml\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1746229782147
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from detectron2.engine import DefaultTrainer, HookBase\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine.hooks import BestCheckpointer\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.data.datasets import register_pascal_voc\n",
        "from detectron2.evaluation import PascalVOCDetectionEvaluator\n",
        "from detectron2.utils.events import get_event_storage\n",
        "from clearml import Task\n",
        "from detectron2.data import transforms as T\n",
        "from detectron2.data import DatasetMapper\n",
        "from detectron2.data import DatasetCatalog\n",
        "import math\n",
        "\n",
        "from numbers import Number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1746229953281
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading config /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"
          ]
        }
      ],
      "source": [
        "epochs=12\n",
        "cfg = get_cfg()\n",
        "\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_50_FPN_1x.yaml\"))\n",
        "\n",
        "\n",
        "voc_root = \"VOCdevkit\"\n",
        "year = 2012\n",
        "\n",
        "for split in [\"train\", \"val\"]:\n",
        "    register_pascal_voc(\n",
        "        f\"voc_{str(split)}\",\n",
        "        os.path.join(voc_root, f\"VOC{str(year)}\"),\n",
        "        split,\n",
        "        year\n",
        "    )\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\n",
        "    model_zoo.get_config_file(\n",
        "        \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"\n",
        "    )\n",
        ")\n",
        "\n",
        "cfg.DATASETS.TRAIN = (\"voc_train\",)\n",
        "cfg.DATASETS.TEST = (\"voc_val\",)\n",
        "\n",
        "\n",
        "dataset_len = len(DatasetCatalog.get(cfg.DATASETS.TRAIN[0]))\n",
        "\n",
        "iters_per_epoch = math.ceil(dataset_len / cfg.SOLVER.IMS_PER_BATCH)\n",
        "epochs = 20\n",
        "\n",
        "\n",
        "cfg.SOLVER.MAX_ITER = epochs * iters_per_epoch\n",
        "cfg.TEST.EVAL_PERIOD = iters_per_epoch\n",
        "\n",
        "\n",
        "cfg.INPUT.MIN_SIZE_TRAIN    = (640, 672, 704, 736, 768, 800)\n",
        "cfg.INPUT.MAX_SIZE_TRAIN    = 1333\n",
        "cfg.INPUT.MIN_SIZE_TEST     = 800\n",
        "cfg.INPUT.MAX_SIZE_TEST     = 1333\n",
        "cfg.INPUT.RANDOM_FLIP       = \"horizontal\"\n",
        "\n",
        "\n",
        "cfg.DATALOADER.NUM_WORKERS = 8\n",
        "\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4\n",
        "cfg.SOLVER.BASE_LR      = 0.01 * (cfg.SOLVER.IMS_PER_BATCH / 16)\n",
        "cfg.SOLVER.WEIGHT_DECAY = 0.0001\n",
        "cfg.SOLVER.STEPS = (\n",
        "    int(0.7 * cfg.SOLVER.MAX_ITER),\n",
        "    int(0.9 * cfg.SOLVER.MAX_ITER),\n",
        ")\n",
        "cfg.SOLVER.GAMMA = 0.1\n",
        "cfg.SOLVER.WARMUP_METHOD       = \"linear\"\n",
        "cfg.SOLVER.WARMUP_FACTOR       = 1.0 / 1e3\n",
        "cfg.SOLVER.WARMUP_ITERS        = 1000\n",
        "cfg.SOLVER.WARMUP_START_LR     = 0.0\n",
        "\n",
        "cfg.MODEL.RETINANET.NUM_CLASSES = 20\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n",
        "    \"COCO-Detection/retinanet_R_50_FPN_1x.yaml\"\n",
        ")\n",
        "cfg.OUTPUT_DIR = \"output\"\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1746229953348
        }
      },
      "outputs": [],
      "source": [
        "class ClearMLHook(HookBase):\n",
        "    def __init__(self):\n",
        "        self.logger = Task.current_task().get_logger()\n",
        "    def after_step(self):\n",
        "        storage = get_event_storage()\n",
        "        for name, value in storage.latest().items():\n",
        "            if isinstance(value, Number):\n",
        "                self.logger.report_scalar(name, \"train\", iteration=storage.iter, value=float(value))\n",
        "\n",
        "\n",
        "class Trainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "        if output_folder is None:\n",
        "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "        return PascalVOCDetectionEvaluator(dataset_name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1746229953405
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dirname: VOCdevkit/VOC2012\n",
            "split: val\n",
            "thing_classes: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
            "year: 2012 <class 'int'>\n"
          ]
        }
      ],
      "source": [
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "meta = MetadataCatalog.get(\"voc_val\")\n",
        "print(\"dirname:\",    meta.dirname)\n",
        "print(\"split:\",      meta.split)\n",
        "print(\"thing_classes:\", meta.thing_classes)\n",
        "print(\"year:\",       meta.year, type(meta.year))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RetinaNet-Detectron2.ipynb   downloads\r\n",
            "RetinaNetTraining.ipynb      output\r\n",
            "VOCdevkit\t\t     retinanet-detectron2.ipynb.amltmp\r\n",
            "VOCtrainval_11-May-2012.tar  retinanettraining.ipynb.amltmp\r\n",
            "data\t\t\t     runs\r\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1746229957788
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ClearML Task: overwriting (reusing) task id=3a544a46e86b4ea9ac6367c59cf60493\n",
            "2025-05-02 23:52:36,711 - clearml.Repository Detection - WARNING - Failed accessing the jupyter server(s): []\n",
            "2025-05-02 23:52:36,714 - clearml.Task - INFO - No repository found, storing script code instead\n",
            "ClearML results page: https://app.clear.ml/projects/31ab205b5fdb489d9ad1b4ed44a65563/experiments/3a544a46e86b4ea9ac6367c59cf60493/output/log\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'VERSION': 2,\n",
              " 'MODEL': {'LOAD_PROPOSALS': False,\n",
              "  'MASK_ON': False,\n",
              "  'KEYPOINT_ON': False,\n",
              "  'DEVICE': 'cuda',\n",
              "  'META_ARCHITECTURE': 'GeneralizedRCNN',\n",
              "  'WEIGHTS': 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_1x/190397773/model_final_bfca0b.pkl',\n",
              "  'PIXEL_MEAN': [103.53, 116.28, 123.675],\n",
              "  'PIXEL_STD': [1.0, 1.0, 1.0],\n",
              "  'BACKBONE': {'NAME': 'build_resnet_fpn_backbone', 'FREEZE_AT': 2},\n",
              "  'FPN': {'IN_FEATURES': ['res2', 'res3', 'res4', 'res5'],\n",
              "   'OUT_CHANNELS': 256,\n",
              "   'NORM': '',\n",
              "   'FUSE_TYPE': 'sum'},\n",
              "  'PROPOSAL_GENERATOR': {'NAME': 'RPN', 'MIN_SIZE': 0},\n",
              "  'ANCHOR_GENERATOR': {'NAME': 'DefaultAnchorGenerator',\n",
              "   'SIZES': [[32], [64], [128], [256], [512]],\n",
              "   'ASPECT_RATIOS': [[0.5, 1.0, 2.0]],\n",
              "   'ANGLES': [[-90, 0, 90]],\n",
              "   'OFFSET': 0.0},\n",
              "  'RPN': {'HEAD_NAME': 'StandardRPNHead',\n",
              "   'IN_FEATURES': ['p2', 'p3', 'p4', 'p5', 'p6'],\n",
              "   'BOUNDARY_THRESH': -1,\n",
              "   'IOU_THRESHOLDS': [0.3, 0.7],\n",
              "   'IOU_LABELS': [0, -1, 1],\n",
              "   'BATCH_SIZE_PER_IMAGE': 256,\n",
              "   'POSITIVE_FRACTION': 0.5,\n",
              "   'BBOX_REG_LOSS_TYPE': 'smooth_l1',\n",
              "   'BBOX_REG_LOSS_WEIGHT': 1.0,\n",
              "   'BBOX_REG_WEIGHTS': (1.0, 1.0, 1.0, 1.0),\n",
              "   'SMOOTH_L1_BETA': 0.0,\n",
              "   'LOSS_WEIGHT': 1.0,\n",
              "   'PRE_NMS_TOPK_TRAIN': 2000,\n",
              "   'PRE_NMS_TOPK_TEST': 1000,\n",
              "   'POST_NMS_TOPK_TRAIN': 1000,\n",
              "   'POST_NMS_TOPK_TEST': 1000,\n",
              "   'NMS_THRESH': 0.7,\n",
              "   'CONV_DIMS': [-1]},\n",
              "  'ROI_HEADS': {'NAME': 'StandardROIHeads',\n",
              "   'NUM_CLASSES': 80,\n",
              "   'IN_FEATURES': ['p2', 'p3', 'p4', 'p5'],\n",
              "   'IOU_THRESHOLDS': [0.5],\n",
              "   'IOU_LABELS': [0, 1],\n",
              "   'BATCH_SIZE_PER_IMAGE': 512,\n",
              "   'POSITIVE_FRACTION': 0.25,\n",
              "   'SCORE_THRESH_TEST': 0.05,\n",
              "   'NMS_THRESH_TEST': 0.5,\n",
              "   'PROPOSAL_APPEND_GT': True},\n",
              "  'ROI_BOX_HEAD': {'NAME': 'FastRCNNConvFCHead',\n",
              "   'BBOX_REG_LOSS_TYPE': 'smooth_l1',\n",
              "   'BBOX_REG_LOSS_WEIGHT': 1.0,\n",
              "   'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),\n",
              "   'SMOOTH_L1_BETA': 0.0,\n",
              "   'POOLER_RESOLUTION': 7,\n",
              "   'POOLER_SAMPLING_RATIO': 0,\n",
              "   'POOLER_TYPE': 'ROIAlignV2',\n",
              "   'NUM_FC': 2,\n",
              "   'FC_DIM': 1024,\n",
              "   'NUM_CONV': 0,\n",
              "   'CONV_DIM': 256,\n",
              "   'NORM': '',\n",
              "   'CLS_AGNOSTIC_BBOX_REG': False,\n",
              "   'TRAIN_ON_PRED_BOXES': False,\n",
              "   'USE_FED_LOSS': False,\n",
              "   'USE_SIGMOID_CE': False,\n",
              "   'FED_LOSS_FREQ_WEIGHT_POWER': 0.5,\n",
              "   'FED_LOSS_NUM_CLASSES': 50},\n",
              "  'ROI_BOX_CASCADE_HEAD': {'BBOX_REG_WEIGHTS': ((10.0, 10.0, 5.0, 5.0),\n",
              "    (20.0, 20.0, 10.0, 10.0),\n",
              "    (30.0, 30.0, 15.0, 15.0)),\n",
              "   'IOUS': (0.5, 0.6, 0.7)},\n",
              "  'ROI_MASK_HEAD': {'NAME': 'MaskRCNNConvUpsampleHead',\n",
              "   'POOLER_RESOLUTION': 14,\n",
              "   'POOLER_SAMPLING_RATIO': 0,\n",
              "   'NUM_CONV': 4,\n",
              "   'CONV_DIM': 256,\n",
              "   'NORM': '',\n",
              "   'CLS_AGNOSTIC_MASK': False,\n",
              "   'POOLER_TYPE': 'ROIAlignV2'},\n",
              "  'ROI_KEYPOINT_HEAD': {'NAME': 'KRCNNConvDeconvUpsampleHead',\n",
              "   'POOLER_RESOLUTION': 14,\n",
              "   'POOLER_SAMPLING_RATIO': 0,\n",
              "   'CONV_DIMS': (512, 512, 512, 512, 512, 512, 512, 512),\n",
              "   'NUM_KEYPOINTS': 17,\n",
              "   'MIN_KEYPOINTS_PER_IMAGE': 1,\n",
              "   'NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS': True,\n",
              "   'LOSS_WEIGHT': 1.0,\n",
              "   'POOLER_TYPE': 'ROIAlignV2'},\n",
              "  'SEM_SEG_HEAD': {'NAME': 'SemSegFPNHead',\n",
              "   'IN_FEATURES': ['p2', 'p3', 'p4', 'p5'],\n",
              "   'IGNORE_VALUE': 255,\n",
              "   'NUM_CLASSES': 54,\n",
              "   'CONVS_DIM': 128,\n",
              "   'COMMON_STRIDE': 4,\n",
              "   'NORM': 'GN',\n",
              "   'LOSS_WEIGHT': 1.0},\n",
              "  'PANOPTIC_FPN': {'INSTANCE_LOSS_WEIGHT': 1.0,\n",
              "   'COMBINE': {'ENABLED': True,\n",
              "    'OVERLAP_THRESH': 0.5,\n",
              "    'STUFF_AREA_LIMIT': 4096,\n",
              "    'INSTANCES_CONFIDENCE_THRESH': 0.5}},\n",
              "  'RETINANET': {'NUM_CLASSES': 20,\n",
              "   'IN_FEATURES': ['p3', 'p4', 'p5', 'p6', 'p7'],\n",
              "   'NUM_CONVS': 4,\n",
              "   'IOU_THRESHOLDS': [0.4, 0.5],\n",
              "   'IOU_LABELS': [0, -1, 1],\n",
              "   'PRIOR_PROB': 0.01,\n",
              "   'SCORE_THRESH_TEST': 0.05,\n",
              "   'TOPK_CANDIDATES_TEST': 1000,\n",
              "   'NMS_THRESH_TEST': 0.5,\n",
              "   'BBOX_REG_WEIGHTS': (1.0, 1.0, 1.0, 1.0),\n",
              "   'FOCAL_LOSS_GAMMA': 2.0,\n",
              "   'FOCAL_LOSS_ALPHA': 0.25,\n",
              "   'SMOOTH_L1_LOSS_BETA': 0.1,\n",
              "   'BBOX_REG_LOSS_TYPE': 'smooth_l1',\n",
              "   'NORM': ''},\n",
              "  'RESNETS': {'DEPTH': 50,\n",
              "   'OUT_FEATURES': ['res2', 'res3', 'res4', 'res5'],\n",
              "   'NUM_GROUPS': 1,\n",
              "   'NORM': 'FrozenBN',\n",
              "   'WIDTH_PER_GROUP': 64,\n",
              "   'STRIDE_IN_1X1': True,\n",
              "   'RES5_DILATION': 1,\n",
              "   'RES2_OUT_CHANNELS': 256,\n",
              "   'STEM_OUT_CHANNELS': 64,\n",
              "   'DEFORM_ON_PER_STAGE': [False, False, False, False],\n",
              "   'DEFORM_MODULATED': False,\n",
              "   'DEFORM_NUM_GROUPS': 1}},\n",
              " 'INPUT': {'MIN_SIZE_TRAIN': (640, 672, 704, 736, 768, 800),\n",
              "  'MIN_SIZE_TRAIN_SAMPLING': 'choice',\n",
              "  'MAX_SIZE_TRAIN': 1333,\n",
              "  'MIN_SIZE_TEST': 800,\n",
              "  'MAX_SIZE_TEST': 1333,\n",
              "  'RANDOM_FLIP': 'horizontal',\n",
              "  'CROP': {'ENABLED': False, 'TYPE': 'relative_range', 'SIZE': [0.9, 0.9]},\n",
              "  'FORMAT': 'BGR',\n",
              "  'MASK_FORMAT': 'polygon'},\n",
              " 'DATASETS': {'TRAIN': ('voc_train',),\n",
              "  'PROPOSAL_FILES_TRAIN': (),\n",
              "  'PRECOMPUTED_PROPOSAL_TOPK_TRAIN': 2000,\n",
              "  'TEST': ('voc_val',),\n",
              "  'PROPOSAL_FILES_TEST': (),\n",
              "  'PRECOMPUTED_PROPOSAL_TOPK_TEST': 1000},\n",
              " 'DATALOADER': {'NUM_WORKERS': 8,\n",
              "  'ASPECT_RATIO_GROUPING': True,\n",
              "  'SAMPLER_TRAIN': 'TrainingSampler',\n",
              "  'REPEAT_THRESHOLD': 0.0,\n",
              "  'REPEAT_SQRT': True,\n",
              "  'FILTER_EMPTY_ANNOTATIONS': True},\n",
              " 'SOLVER': {'LR_SCHEDULER_NAME': 'WarmupMultiStepLR',\n",
              "  'MAX_ITER': 7160,\n",
              "  'BASE_LR': 0.0025,\n",
              "  'BASE_LR_END': 0.0,\n",
              "  'MOMENTUM': 0.9,\n",
              "  'NESTEROV': False,\n",
              "  'WEIGHT_DECAY': 0.0001,\n",
              "  'WEIGHT_DECAY_NORM': 0.0,\n",
              "  'GAMMA': 0.1,\n",
              "  'STEPS': (5012, 6444),\n",
              "  'NUM_DECAYS': 3,\n",
              "  'WARMUP_FACTOR': 0.001,\n",
              "  'WARMUP_ITERS': 1000,\n",
              "  'WARMUP_METHOD': 'linear',\n",
              "  'RESCALE_INTERVAL': False,\n",
              "  'CHECKPOINT_PERIOD': 5000,\n",
              "  'IMS_PER_BATCH': 4,\n",
              "  'REFERENCE_WORLD_SIZE': 0,\n",
              "  'BIAS_LR_FACTOR': 1.0,\n",
              "  'WEIGHT_DECAY_BIAS': None,\n",
              "  'CLIP_GRADIENTS': {'ENABLED': False,\n",
              "   'CLIP_TYPE': 'value',\n",
              "   'CLIP_VALUE': 1.0,\n",
              "   'NORM_TYPE': 2.0},\n",
              "  'AMP': {'ENABLED': False},\n",
              "  'WARMUP_START_LR': 0.0},\n",
              " 'TEST': {'EXPECTED_RESULTS': [],\n",
              "  'EVAL_PERIOD': 358,\n",
              "  'KEYPOINT_OKS_SIGMAS': [],\n",
              "  'DETECTIONS_PER_IMAGE': 100,\n",
              "  'AUG': {'ENABLED': False,\n",
              "   'MIN_SIZES': (400, 500, 600, 700, 800, 900, 1000, 1100, 1200),\n",
              "   'MAX_SIZE': 4000,\n",
              "   'FLIP': True},\n",
              "  'PRECISE_BN': {'ENABLED': False, 'NUM_ITER': 200}},\n",
              " 'OUTPUT_DIR': 'output',\n",
              " 'SEED': -1,\n",
              " 'CUDNN_BENCHMARK': False,\n",
              " 'FLOAT32_PRECISION': '',\n",
              " 'VIS_PERIOD': 0,\n",
              " 'GLOBAL': {'HACK': 1.0}}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "experiment_tags = [\n",
        "    \"model_name:retinanet\",\n",
        "    \"dataset:voc2012\",\n",
        "    \"platform:azureml-notebook\",\n",
        "    \"author:hussain\",\n",
        "    \"account:hussainsyed.dev@outlook.com\",\n",
        "    \"studio:obj-detect-3xc\",\n",
        "    \"detectron2\"\n",
        "]\n",
        "\n",
        "task = Task.init(\n",
        "    project_name=\"CMT318-Object-Detection\",\n",
        "    task_name=\"RetinaNet-Detectron2-Training\",\n",
        "    tags=experiment_tags\n",
        ")\n",
        "\n",
        "task.connect(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1746230030851
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[05/02 23:52:38 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[05/02 23:53:50 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 5717 images left.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some model parameters or buffers are not found in the checkpoint:\n",
            "\u001b[34mbackbone.fpn_lateral2.{bias, weight}\u001b[0m\n",
            "\u001b[34mbackbone.fpn_output2.{bias, weight}\u001b[0m\n",
            "\u001b[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}\u001b[0m\n",
            "\u001b[34mproposal_generator.rpn_head.conv.{bias, weight}\u001b[0m\n",
            "\u001b[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_head.fc1.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_head.fc2.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
            "The checkpoint state_dict contains keys that are not used by the model:\n",
            "  \u001b[35mpixel_mean\u001b[0m\n",
            "  \u001b[35mpixel_std\u001b[0m\n",
            "  \u001b[35mhead.cls_subnet.0.{bias, weight}\u001b[0m\n",
            "  \u001b[35mhead.cls_subnet.2.{bias, weight}\u001b[0m\n",
            "  \u001b[35mhead.cls_subnet.4.{bias, weight}\u001b[0m\n",
            "  \u001b[35mhead.cls_subnet.6.{bias, weight}\u001b[0m\n",
            "  \u001b[35mhead.bbox_subnet.0.{bias, weight}\u001b[0m\n",
            "  \u001b[35mhead.bbox_subnet.2.{bias, weight}\u001b[0m\n",
            "  \u001b[35mhead.bbox_subnet.4.{bias, weight}\u001b[0m\n",
            "  \u001b[35mhead.bbox_subnet.6.{bias, weight}\u001b[0m\n",
            "  \u001b[35mhead.cls_score.{bias, weight}\u001b[0m\n",
            "  \u001b[35mhead.bbox_pred.{bias, weight}\u001b[0m\n",
            "  \u001b[35mbackbone.top_block.p6.{bias, weight}\u001b[0m\n",
            "  \u001b[35mbackbone.top_block.p7.{bias, weight}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(cfg)\n",
        "\n",
        "trainer.register_hooks([\n",
        "    BestCheckpointer(\n",
        "        eval_period=cfg.TEST.EVAL_PERIOD,\n",
        "        checkpointer=trainer.checkpointer,\n",
        "        val_metric=\"bbox/AP50\",\n",
        "        mode=\"max\",\n",
        "        file_prefix=\"model_best\"\n",
        "    ),\n",
        "    ClearMLHook()\n",
        "])\n",
        "trainer.resume_or_load(resume=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1746228914167
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[05/02 23:53:50 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[05/02 23:54:07 d2.utils.events]: \u001b[0m eta: 1:33:45  iter: 19  total_loss: 4.858  loss_cls: 4.123  loss_box_reg: 0.002125  loss_rpn_cls: 0.6728  loss_rpn_loc: 0.04768    time: 0.7896  last_time: 0.8347  data_time: 0.0219  last_data_time: 0.0084   lr: 4.9952e-05  max_mem: 4873M\n",
            "\u001b[32m[05/02 23:54:24 d2.utils.events]: \u001b[0m eta: 1:39:16  iter: 39  total_loss: 1.069  loss_cls: 0.4115  loss_box_reg: 0.01702  loss_rpn_cls: 0.6158  loss_rpn_loc: 0.03535    time: 0.8253  last_time: 0.7611  data_time: 0.0082  last_data_time: 0.0068   lr: 9.9903e-05  max_mem: 4873M\n",
            "\u001b[32m[05/02 23:54:42 d2.utils.events]: \u001b[0m eta: 1:41:22  iter: 59  total_loss: 0.9351  loss_cls: 0.3369  loss_box_reg: 0.05776  loss_rpn_cls: 0.4821  loss_rpn_loc: 0.04997    time: 0.8444  last_time: 0.8657  data_time: 0.0082  last_data_time: 0.0079   lr: 0.00014985  max_mem: 4873M\n",
            "\u001b[32m[05/02 23:55:00 d2.utils.events]: \u001b[0m eta: 1:42:03  iter: 79  total_loss: 0.604  loss_cls: 0.1824  loss_box_reg: 0.07336  loss_rpn_cls: 0.3105  loss_rpn_loc: 0.03548    time: 0.8548  last_time: 0.7857  data_time: 0.0079  last_data_time: 0.0076   lr: 0.0001998  max_mem: 4873M\n",
            "\u001b[32m[05/02 23:55:18 d2.utils.events]: \u001b[0m eta: 1:42:44  iter: 99  total_loss: 0.6721  loss_cls: 0.301  loss_box_reg: 0.1266  loss_rpn_cls: 0.2002  loss_rpn_loc: 0.03051    time: 0.8629  last_time: 0.8295  data_time: 0.0081  last_data_time: 0.0084   lr: 0.00024975  max_mem: 4873M\n",
            "\u001b[32m[05/02 23:55:36 d2.utils.events]: \u001b[0m eta: 1:42:53  iter: 119  total_loss: 0.7392  loss_cls: 0.3375  loss_box_reg: 0.1696  loss_rpn_cls: 0.1419  loss_rpn_loc: 0.03318    time: 0.8701  last_time: 0.9167  data_time: 0.0081  last_data_time: 0.0074   lr: 0.0002997  max_mem: 4873M\n",
            "\u001b[32m[05/02 23:55:55 d2.utils.events]: \u001b[0m eta: 1:42:47  iter: 139  total_loss: 0.6313  loss_cls: 0.3225  loss_box_reg: 0.1528  loss_rpn_cls: 0.1166  loss_rpn_loc: 0.03894    time: 0.8770  last_time: 0.9193  data_time: 0.0082  last_data_time: 0.0082   lr: 0.00034965  max_mem: 4873M\n",
            "\u001b[32m[05/02 23:56:12 d2.utils.events]: \u001b[0m eta: 1:42:33  iter: 159  total_loss: 0.7775  loss_cls: 0.3714  loss_box_reg: 0.1953  loss_rpn_cls: 0.1071  loss_rpn_loc: 0.043    time: 0.8769  last_time: 0.9703  data_time: 0.0082  last_data_time: 0.0104   lr: 0.0003996  max_mem: 4873M\n",
            "\u001b[32m[05/02 23:56:30 d2.utils.events]: \u001b[0m eta: 1:42:40  iter: 179  total_loss: 0.5505  loss_cls: 0.2708  loss_box_reg: 0.1579  loss_rpn_cls: 0.08969  loss_rpn_loc: 0.03691    time: 0.8802  last_time: 0.8983  data_time: 0.0079  last_data_time: 0.0096   lr: 0.00044955  max_mem: 4873M\n",
            "\u001b[32m[05/02 23:56:49 d2.utils.events]: \u001b[0m eta: 1:42:48  iter: 199  total_loss: 0.6525  loss_cls: 0.3311  loss_box_reg: 0.1901  loss_rpn_cls: 0.0772  loss_rpn_loc: 0.0372    time: 0.8838  last_time: 0.9830  data_time: 0.0079  last_data_time: 0.0093   lr: 0.0004995  max_mem: 4874M\n",
            "\u001b[32m[05/02 23:57:07 d2.utils.events]: \u001b[0m eta: 1:42:47  iter: 219  total_loss: 0.6121  loss_cls: 0.3145  loss_box_reg: 0.1967  loss_rpn_cls: 0.08071  loss_rpn_loc: 0.03735    time: 0.8852  last_time: 0.9283  data_time: 0.0084  last_data_time: 0.0084   lr: 0.00054945  max_mem: 4874M\n",
            "\u001b[32m[05/02 23:57:26 d2.utils.events]: \u001b[0m eta: 1:42:41  iter: 239  total_loss: 0.6415  loss_cls: 0.3129  loss_box_reg: 0.1941  loss_rpn_cls: 0.08174  loss_rpn_loc: 0.03431    time: 0.8881  last_time: 0.9874  data_time: 0.0081  last_data_time: 0.0034   lr: 0.0005994  max_mem: 4874M\n",
            "\u001b[32m[05/02 23:57:44 d2.utils.events]: \u001b[0m eta: 1:42:36  iter: 259  total_loss: 0.5993  loss_cls: 0.2769  loss_box_reg: 0.2086  loss_rpn_cls: 0.07382  loss_rpn_loc: 0.03735    time: 0.8904  last_time: 0.7877  data_time: 0.0080  last_data_time: 0.0066   lr: 0.00064935  max_mem: 4874M\n",
            "\u001b[32m[05/02 23:58:02 d2.utils.events]: \u001b[0m eta: 1:42:36  iter: 279  total_loss: 0.6836  loss_cls: 0.3465  loss_box_reg: 0.2544  loss_rpn_cls: 0.07044  loss_rpn_loc: 0.03705    time: 0.8912  last_time: 0.8775  data_time: 0.0081  last_data_time: 0.0091   lr: 0.0006993  max_mem: 4874M\n",
            "\u001b[32m[05/02 23:58:21 d2.utils.events]: \u001b[0m eta: 1:42:47  iter: 299  total_loss: 0.6678  loss_cls: 0.3414  loss_box_reg: 0.225  loss_rpn_cls: 0.06432  loss_rpn_loc: 0.03421    time: 0.8934  last_time: 0.8728  data_time: 0.0088  last_data_time: 0.0029   lr: 0.00074925  max_mem: 4874M\n",
            "\u001b[32m[05/02 23:58:39 d2.utils.events]: \u001b[0m eta: 1:42:59  iter: 319  total_loss: 0.5351  loss_cls: 0.2473  loss_box_reg: 0.1936  loss_rpn_cls: 0.05473  loss_rpn_loc: 0.03334    time: 0.8952  last_time: 0.9192  data_time: 0.0083  last_data_time: 0.0080   lr: 0.0007992  max_mem: 4874M\n",
            "\u001b[32m[05/02 23:58:58 d2.utils.events]: \u001b[0m eta: 1:42:58  iter: 339  total_loss: 0.543  loss_cls: 0.2721  loss_box_reg: 0.225  loss_rpn_cls: 0.04742  loss_rpn_loc: 0.03117    time: 0.8977  last_time: 0.9503  data_time: 0.0084  last_data_time: 0.0092   lr: 0.00084915  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:02:01 d2.data.build]: \u001b[0mDistribution of instances among all 20 categories:\n",
            "\u001b[36m|  category   | #instances   |  category   | #instances   |  category  | #instances   |\n",
            "|:-----------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
            "|  aeroplane  | 484          |   bicycle   | 380          |    bird    | 629          |\n",
            "|    boat     | 491          |   bottle    | 733          |    bus     | 320          |\n",
            "|     car     | 1173         |     cat     | 618          |   chair    | 1449         |\n",
            "|     cow     | 347          | diningtable | 374          |    dog     | 773          |\n",
            "|    horse    | 373          |  motorbike  | 376          |   person   | 5110         |\n",
            "| pottedplant | 542          |    sheep    | 485          |    sofa    | 387          |\n",
            "|    train    | 329          |  tvmonitor  | 414          |            |              |\n",
            "|    total    | 15787        |             |              |            |              |\u001b[0m\n",
            "\u001b[32m[05/03 00:02:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/03 00:02:01 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/03 00:02:01 d2.data.common]: \u001b[0mSerializing 5823 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/03 00:02:01 d2.data.common]: \u001b[0mSerialized dataset takes 2.67 MiB\n",
            "\u001b[32m[05/03 00:02:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 5823 batches\n",
            "\u001b[32m[05/03 00:02:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/5823. Dataloading: 0.0013 s/iter. Inference: 0.0991 s/iter. Eval: 0.0003 s/iter. Total: 0.1008 s/iter. ETA=0:09:45\n",
            "\u001b[32m[05/03 00:02:08 d2.evaluation.evaluator]: \u001b[0mInference done 62/5823. Dataloading: 0.0015 s/iter. Inference: 0.0971 s/iter. Eval: 0.0004 s/iter. Total: 0.0991 s/iter. ETA=0:09:30\n",
            "\u001b[32m[05/03 00:02:13 d2.evaluation.evaluator]: \u001b[0mInference done 112/5823. Dataloading: 0.0015 s/iter. Inference: 0.0984 s/iter. Eval: 0.0004 s/iter. Total: 0.1005 s/iter. ETA=0:09:33\n",
            "\u001b[32m[05/03 00:02:18 d2.evaluation.evaluator]: \u001b[0mInference done 162/5823. Dataloading: 0.0015 s/iter. Inference: 0.0984 s/iter. Eval: 0.0004 s/iter. Total: 0.1004 s/iter. ETA=0:09:28\n",
            "\u001b[32m[05/03 00:02:23 d2.evaluation.evaluator]: \u001b[0mInference done 212/5823. Dataloading: 0.0015 s/iter. Inference: 0.0986 s/iter. Eval: 0.0004 s/iter. Total: 0.1006 s/iter. ETA=0:09:24\n",
            "\u001b[32m[05/03 00:02:28 d2.evaluation.evaluator]: \u001b[0mInference done 262/5823. Dataloading: 0.0015 s/iter. Inference: 0.0986 s/iter. Eval: 0.0004 s/iter. Total: 0.1006 s/iter. ETA=0:09:19\n",
            "\u001b[32m[05/03 00:02:33 d2.evaluation.evaluator]: \u001b[0mInference done 312/5823. Dataloading: 0.0015 s/iter. Inference: 0.0987 s/iter. Eval: 0.0004 s/iter. Total: 0.1007 s/iter. ETA=0:09:15\n",
            "\u001b[32m[05/03 00:02:38 d2.evaluation.evaluator]: \u001b[0mInference done 362/5823. Dataloading: 0.0016 s/iter. Inference: 0.0988 s/iter. Eval: 0.0004 s/iter. Total: 0.1008 s/iter. ETA=0:09:10\n",
            "\u001b[32m[05/03 00:02:43 d2.evaluation.evaluator]: \u001b[0mInference done 411/5823. Dataloading: 0.0016 s/iter. Inference: 0.0990 s/iter. Eval: 0.0004 s/iter. Total: 0.1010 s/iter. ETA=0:09:06\n",
            "\u001b[32m[05/03 00:02:48 d2.evaluation.evaluator]: \u001b[0mInference done 461/5823. Dataloading: 0.0016 s/iter. Inference: 0.0990 s/iter. Eval: 0.0004 s/iter. Total: 0.1011 s/iter. ETA=0:09:02\n",
            "\u001b[32m[05/03 00:02:53 d2.evaluation.evaluator]: \u001b[0mInference done 510/5823. Dataloading: 0.0016 s/iter. Inference: 0.0991 s/iter. Eval: 0.0004 s/iter. Total: 0.1012 s/iter. ETA=0:08:57\n",
            "\u001b[32m[05/03 00:02:58 d2.evaluation.evaluator]: \u001b[0mInference done 559/5823. Dataloading: 0.0016 s/iter. Inference: 0.0993 s/iter. Eval: 0.0004 s/iter. Total: 0.1014 s/iter. ETA=0:08:53\n",
            "\u001b[32m[05/03 00:03:04 d2.evaluation.evaluator]: \u001b[0mInference done 608/5823. Dataloading: 0.0016 s/iter. Inference: 0.0994 s/iter. Eval: 0.0005 s/iter. Total: 0.1015 s/iter. ETA=0:08:49\n",
            "\u001b[32m[05/03 00:03:09 d2.evaluation.evaluator]: \u001b[0mInference done 657/5823. Dataloading: 0.0016 s/iter. Inference: 0.0995 s/iter. Eval: 0.0005 s/iter. Total: 0.1016 s/iter. ETA=0:08:44\n",
            "\u001b[32m[05/03 00:03:14 d2.evaluation.evaluator]: \u001b[0mInference done 706/5823. Dataloading: 0.0016 s/iter. Inference: 0.0995 s/iter. Eval: 0.0005 s/iter. Total: 0.1016 s/iter. ETA=0:08:40\n",
            "\u001b[32m[05/03 00:03:19 d2.evaluation.evaluator]: \u001b[0mInference done 755/5823. Dataloading: 0.0016 s/iter. Inference: 0.0996 s/iter. Eval: 0.0005 s/iter. Total: 0.1017 s/iter. ETA=0:08:35\n",
            "\u001b[32m[05/03 00:03:24 d2.evaluation.evaluator]: \u001b[0mInference done 804/5823. Dataloading: 0.0016 s/iter. Inference: 0.0997 s/iter. Eval: 0.0005 s/iter. Total: 0.1018 s/iter. ETA=0:08:31\n",
            "\u001b[32m[05/03 00:03:29 d2.evaluation.evaluator]: \u001b[0mInference done 854/5823. Dataloading: 0.0016 s/iter. Inference: 0.0997 s/iter. Eval: 0.0005 s/iter. Total: 0.1018 s/iter. ETA=0:08:25\n",
            "\u001b[32m[05/03 00:03:34 d2.evaluation.evaluator]: \u001b[0mInference done 904/5823. Dataloading: 0.0016 s/iter. Inference: 0.0997 s/iter. Eval: 0.0005 s/iter. Total: 0.1018 s/iter. ETA=0:08:20\n",
            "\u001b[32m[05/03 00:03:39 d2.evaluation.evaluator]: \u001b[0mInference done 953/5823. Dataloading: 0.0016 s/iter. Inference: 0.0998 s/iter. Eval: 0.0005 s/iter. Total: 0.1019 s/iter. ETA=0:08:16\n",
            "\u001b[32m[05/03 00:03:44 d2.evaluation.evaluator]: \u001b[0mInference done 1002/5823. Dataloading: 0.0016 s/iter. Inference: 0.0998 s/iter. Eval: 0.0005 s/iter. Total: 0.1019 s/iter. ETA=0:08:11\n",
            "\u001b[32m[05/03 00:03:49 d2.evaluation.evaluator]: \u001b[0mInference done 1050/5823. Dataloading: 0.0016 s/iter. Inference: 0.0999 s/iter. Eval: 0.0005 s/iter. Total: 0.1020 s/iter. ETA=0:08:06\n",
            "\u001b[32m[05/03 00:03:54 d2.evaluation.evaluator]: \u001b[0mInference done 1100/5823. Dataloading: 0.0016 s/iter. Inference: 0.0999 s/iter. Eval: 0.0005 s/iter. Total: 0.1020 s/iter. ETA=0:08:01\n",
            "\u001b[32m[05/03 00:03:59 d2.evaluation.evaluator]: \u001b[0mInference done 1149/5823. Dataloading: 0.0016 s/iter. Inference: 0.0999 s/iter. Eval: 0.0005 s/iter. Total: 0.1020 s/iter. ETA=0:07:56\n",
            "\u001b[32m[05/03 00:04:04 d2.evaluation.evaluator]: \u001b[0mInference done 1198/5823. Dataloading: 0.0016 s/iter. Inference: 0.0999 s/iter. Eval: 0.0004 s/iter. Total: 0.1020 s/iter. ETA=0:07:51\n",
            "\u001b[32m[05/03 00:04:09 d2.evaluation.evaluator]: \u001b[0mInference done 1246/5823. Dataloading: 0.0016 s/iter. Inference: 0.1001 s/iter. Eval: 0.0004 s/iter. Total: 0.1022 s/iter. ETA=0:07:47\n",
            "\u001b[32m[05/03 00:04:14 d2.evaluation.evaluator]: \u001b[0mInference done 1294/5823. Dataloading: 0.0016 s/iter. Inference: 0.1002 s/iter. Eval: 0.0004 s/iter. Total: 0.1023 s/iter. ETA=0:07:43\n",
            "\u001b[32m[05/03 00:04:19 d2.evaluation.evaluator]: \u001b[0mInference done 1342/5823. Dataloading: 0.0016 s/iter. Inference: 0.1003 s/iter. Eval: 0.0004 s/iter. Total: 0.1024 s/iter. ETA=0:07:38\n",
            "\u001b[32m[05/03 00:04:24 d2.evaluation.evaluator]: \u001b[0mInference done 1390/5823. Dataloading: 0.0016 s/iter. Inference: 0.1003 s/iter. Eval: 0.0004 s/iter. Total: 0.1024 s/iter. ETA=0:07:34\n",
            "\u001b[32m[05/03 00:04:29 d2.evaluation.evaluator]: \u001b[0mInference done 1438/5823. Dataloading: 0.0016 s/iter. Inference: 0.1004 s/iter. Eval: 0.0004 s/iter. Total: 0.1025 s/iter. ETA=0:07:29\n",
            "\u001b[32m[05/03 00:04:34 d2.evaluation.evaluator]: \u001b[0mInference done 1486/5823. Dataloading: 0.0016 s/iter. Inference: 0.1005 s/iter. Eval: 0.0004 s/iter. Total: 0.1026 s/iter. ETA=0:07:25\n",
            "\u001b[32m[05/03 00:04:39 d2.evaluation.evaluator]: \u001b[0mInference done 1535/5823. Dataloading: 0.0016 s/iter. Inference: 0.1006 s/iter. Eval: 0.0004 s/iter. Total: 0.1027 s/iter. ETA=0:07:20\n",
            "\u001b[32m[05/03 00:04:44 d2.evaluation.evaluator]: \u001b[0mInference done 1583/5823. Dataloading: 0.0016 s/iter. Inference: 0.1006 s/iter. Eval: 0.0004 s/iter. Total: 0.1027 s/iter. ETA=0:07:15\n",
            "\u001b[32m[05/03 00:04:49 d2.evaluation.evaluator]: \u001b[0mInference done 1631/5823. Dataloading: 0.0016 s/iter. Inference: 0.1007 s/iter. Eval: 0.0004 s/iter. Total: 0.1028 s/iter. ETA=0:07:10\n",
            "\u001b[32m[05/03 00:04:55 d2.evaluation.evaluator]: \u001b[0mInference done 1679/5823. Dataloading: 0.0016 s/iter. Inference: 0.1008 s/iter. Eval: 0.0004 s/iter. Total: 0.1029 s/iter. ETA=0:07:06\n",
            "\u001b[32m[05/03 00:05:00 d2.evaluation.evaluator]: \u001b[0mInference done 1727/5823. Dataloading: 0.0016 s/iter. Inference: 0.1008 s/iter. Eval: 0.0004 s/iter. Total: 0.1029 s/iter. ETA=0:07:01\n",
            "\u001b[32m[05/03 00:05:05 d2.evaluation.evaluator]: \u001b[0mInference done 1776/5823. Dataloading: 0.0016 s/iter. Inference: 0.1008 s/iter. Eval: 0.0004 s/iter. Total: 0.1029 s/iter. ETA=0:06:56\n",
            "\u001b[32m[05/03 00:05:10 d2.evaluation.evaluator]: \u001b[0mInference done 1823/5823. Dataloading: 0.0016 s/iter. Inference: 0.1009 s/iter. Eval: 0.0004 s/iter. Total: 0.1030 s/iter. ETA=0:06:52\n",
            "\u001b[32m[05/03 00:05:15 d2.evaluation.evaluator]: \u001b[0mInference done 1872/5823. Dataloading: 0.0016 s/iter. Inference: 0.1010 s/iter. Eval: 0.0004 s/iter. Total: 0.1031 s/iter. ETA=0:06:47\n",
            "\u001b[32m[05/03 00:05:20 d2.evaluation.evaluator]: \u001b[0mInference done 1920/5823. Dataloading: 0.0016 s/iter. Inference: 0.1010 s/iter. Eval: 0.0004 s/iter. Total: 0.1031 s/iter. ETA=0:06:42\n",
            "\u001b[32m[05/03 00:05:25 d2.evaluation.evaluator]: \u001b[0mInference done 1968/5823. Dataloading: 0.0016 s/iter. Inference: 0.1010 s/iter. Eval: 0.0004 s/iter. Total: 0.1032 s/iter. ETA=0:06:37\n",
            "\u001b[32m[05/03 00:05:30 d2.evaluation.evaluator]: \u001b[0mInference done 2017/5823. Dataloading: 0.0016 s/iter. Inference: 0.1011 s/iter. Eval: 0.0004 s/iter. Total: 0.1032 s/iter. ETA=0:06:32\n",
            "\u001b[32m[05/03 00:05:35 d2.evaluation.evaluator]: \u001b[0mInference done 2065/5823. Dataloading: 0.0016 s/iter. Inference: 0.1011 s/iter. Eval: 0.0004 s/iter. Total: 0.1032 s/iter. ETA=0:06:27\n",
            "\u001b[32m[05/03 00:05:40 d2.evaluation.evaluator]: \u001b[0mInference done 2113/5823. Dataloading: 0.0016 s/iter. Inference: 0.1012 s/iter. Eval: 0.0004 s/iter. Total: 0.1033 s/iter. ETA=0:06:23\n",
            "\u001b[32m[05/03 00:05:45 d2.evaluation.evaluator]: \u001b[0mInference done 2161/5823. Dataloading: 0.0016 s/iter. Inference: 0.1012 s/iter. Eval: 0.0004 s/iter. Total: 0.1033 s/iter. ETA=0:06:18\n",
            "\u001b[32m[05/03 00:05:50 d2.evaluation.evaluator]: \u001b[0mInference done 2210/5823. Dataloading: 0.0016 s/iter. Inference: 0.1012 s/iter. Eval: 0.0004 s/iter. Total: 0.1033 s/iter. ETA=0:06:13\n",
            "\u001b[32m[05/03 00:05:55 d2.evaluation.evaluator]: \u001b[0mInference done 2258/5823. Dataloading: 0.0016 s/iter. Inference: 0.1013 s/iter. Eval: 0.0004 s/iter. Total: 0.1034 s/iter. ETA=0:06:08\n",
            "\u001b[32m[05/03 00:06:00 d2.evaluation.evaluator]: \u001b[0mInference done 2305/5823. Dataloading: 0.0016 s/iter. Inference: 0.1013 s/iter. Eval: 0.0004 s/iter. Total: 0.1034 s/iter. ETA=0:06:03\n",
            "\u001b[32m[05/03 00:06:05 d2.evaluation.evaluator]: \u001b[0mInference done 2353/5823. Dataloading: 0.0016 s/iter. Inference: 0.1014 s/iter. Eval: 0.0004 s/iter. Total: 0.1035 s/iter. ETA=0:05:59\n",
            "\u001b[32m[05/03 00:06:10 d2.evaluation.evaluator]: \u001b[0mInference done 2400/5823. Dataloading: 0.0016 s/iter. Inference: 0.1014 s/iter. Eval: 0.0004 s/iter. Total: 0.1035 s/iter. ETA=0:05:54\n",
            "\u001b[32m[05/03 00:06:15 d2.evaluation.evaluator]: \u001b[0mInference done 2447/5823. Dataloading: 0.0016 s/iter. Inference: 0.1015 s/iter. Eval: 0.0004 s/iter. Total: 0.1036 s/iter. ETA=0:05:49\n",
            "\u001b[32m[05/03 00:06:20 d2.evaluation.evaluator]: \u001b[0mInference done 2495/5823. Dataloading: 0.0016 s/iter. Inference: 0.1016 s/iter. Eval: 0.0004 s/iter. Total: 0.1037 s/iter. ETA=0:05:44\n",
            "\u001b[32m[05/03 00:06:25 d2.evaluation.evaluator]: \u001b[0mInference done 2543/5823. Dataloading: 0.0016 s/iter. Inference: 0.1016 s/iter. Eval: 0.0004 s/iter. Total: 0.1037 s/iter. ETA=0:05:40\n",
            "\u001b[32m[05/03 00:06:30 d2.evaluation.evaluator]: \u001b[0mInference done 2590/5823. Dataloading: 0.0016 s/iter. Inference: 0.1016 s/iter. Eval: 0.0004 s/iter. Total: 0.1037 s/iter. ETA=0:05:35\n",
            "\u001b[32m[05/03 00:06:36 d2.evaluation.evaluator]: \u001b[0mInference done 2637/5823. Dataloading: 0.0016 s/iter. Inference: 0.1017 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:05:30\n",
            "\u001b[32m[05/03 00:06:41 d2.evaluation.evaluator]: \u001b[0mInference done 2685/5823. Dataloading: 0.0016 s/iter. Inference: 0.1017 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:05:25\n",
            "\u001b[32m[05/03 00:06:46 d2.evaluation.evaluator]: \u001b[0mInference done 2732/5823. Dataloading: 0.0016 s/iter. Inference: 0.1018 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:05:21\n",
            "\u001b[32m[05/03 00:06:51 d2.evaluation.evaluator]: \u001b[0mInference done 2780/5823. Dataloading: 0.0016 s/iter. Inference: 0.1018 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:05:16\n",
            "\u001b[32m[05/03 00:06:56 d2.evaluation.evaluator]: \u001b[0mInference done 2827/5823. Dataloading: 0.0016 s/iter. Inference: 0.1019 s/iter. Eval: 0.0004 s/iter. Total: 0.1040 s/iter. ETA=0:05:11\n",
            "\u001b[32m[05/03 00:07:01 d2.evaluation.evaluator]: \u001b[0mInference done 2874/5823. Dataloading: 0.0016 s/iter. Inference: 0.1019 s/iter. Eval: 0.0004 s/iter. Total: 0.1040 s/iter. ETA=0:05:06\n",
            "\u001b[32m[05/03 00:07:06 d2.evaluation.evaluator]: \u001b[0mInference done 2921/5823. Dataloading: 0.0016 s/iter. Inference: 0.1020 s/iter. Eval: 0.0004 s/iter. Total: 0.1041 s/iter. ETA=0:05:02\n",
            "\u001b[32m[05/03 00:07:11 d2.evaluation.evaluator]: \u001b[0mInference done 2968/5823. Dataloading: 0.0016 s/iter. Inference: 0.1020 s/iter. Eval: 0.0004 s/iter. Total: 0.1041 s/iter. ETA=0:04:57\n",
            "\u001b[32m[05/03 00:07:16 d2.evaluation.evaluator]: \u001b[0mInference done 3015/5823. Dataloading: 0.0016 s/iter. Inference: 0.1021 s/iter. Eval: 0.0004 s/iter. Total: 0.1042 s/iter. ETA=0:04:52\n",
            "\u001b[32m[05/03 00:07:21 d2.evaluation.evaluator]: \u001b[0mInference done 3062/5823. Dataloading: 0.0016 s/iter. Inference: 0.1021 s/iter. Eval: 0.0004 s/iter. Total: 0.1042 s/iter. ETA=0:04:47\n",
            "\u001b[32m[05/03 00:07:26 d2.evaluation.evaluator]: \u001b[0mInference done 3109/5823. Dataloading: 0.0016 s/iter. Inference: 0.1021 s/iter. Eval: 0.0004 s/iter. Total: 0.1042 s/iter. ETA=0:04:42\n",
            "\u001b[32m[05/03 00:07:31 d2.evaluation.evaluator]: \u001b[0mInference done 3156/5823. Dataloading: 0.0016 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1043 s/iter. ETA=0:04:38\n",
            "\u001b[32m[05/03 00:07:36 d2.evaluation.evaluator]: \u001b[0mInference done 3203/5823. Dataloading: 0.0016 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1043 s/iter. ETA=0:04:33\n",
            "\u001b[32m[05/03 00:07:41 d2.evaluation.evaluator]: \u001b[0mInference done 3251/5823. Dataloading: 0.0016 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1043 s/iter. ETA=0:04:28\n",
            "\u001b[32m[05/03 00:07:46 d2.evaluation.evaluator]: \u001b[0mInference done 3298/5823. Dataloading: 0.0016 s/iter. Inference: 0.1023 s/iter. Eval: 0.0004 s/iter. Total: 0.1044 s/iter. ETA=0:04:23\n",
            "\u001b[32m[05/03 00:07:51 d2.evaluation.evaluator]: \u001b[0mInference done 3345/5823. Dataloading: 0.0016 s/iter. Inference: 0.1023 s/iter. Eval: 0.0004 s/iter. Total: 0.1044 s/iter. ETA=0:04:18\n",
            "\u001b[32m[05/03 00:07:56 d2.evaluation.evaluator]: \u001b[0mInference done 3392/5823. Dataloading: 0.0016 s/iter. Inference: 0.1023 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:04:13\n",
            "\u001b[32m[05/03 00:08:01 d2.evaluation.evaluator]: \u001b[0mInference done 3440/5823. Dataloading: 0.0016 s/iter. Inference: 0.1024 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:04:08\n",
            "\u001b[32m[05/03 00:08:06 d2.evaluation.evaluator]: \u001b[0mInference done 3488/5823. Dataloading: 0.0016 s/iter. Inference: 0.1024 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:04:03\n",
            "\u001b[32m[05/03 00:08:11 d2.evaluation.evaluator]: \u001b[0mInference done 3536/5823. Dataloading: 0.0016 s/iter. Inference: 0.1024 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:03:59\n",
            "\u001b[32m[05/03 00:08:16 d2.evaluation.evaluator]: \u001b[0mInference done 3584/5823. Dataloading: 0.0016 s/iter. Inference: 0.1024 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:03:54\n",
            "\u001b[32m[05/03 00:08:21 d2.evaluation.evaluator]: \u001b[0mInference done 3632/5823. Dataloading: 0.0016 s/iter. Inference: 0.1024 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:03:49\n",
            "\u001b[32m[05/03 00:08:27 d2.evaluation.evaluator]: \u001b[0mInference done 3680/5823. Dataloading: 0.0016 s/iter. Inference: 0.1024 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:03:44\n",
            "\u001b[32m[05/03 00:08:32 d2.evaluation.evaluator]: \u001b[0mInference done 3728/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:03:39\n",
            "\u001b[32m[05/03 00:08:37 d2.evaluation.evaluator]: \u001b[0mInference done 3776/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:03:34\n",
            "\u001b[32m[05/03 00:08:42 d2.evaluation.evaluator]: \u001b[0mInference done 3824/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:03:29\n",
            "\u001b[32m[05/03 00:08:47 d2.evaluation.evaluator]: \u001b[0mInference done 3871/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:03:24\n",
            "\u001b[32m[05/03 00:08:52 d2.evaluation.evaluator]: \u001b[0mInference done 3918/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:03:19\n",
            "\u001b[32m[05/03 00:08:57 d2.evaluation.evaluator]: \u001b[0mInference done 3966/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:03:14\n",
            "\u001b[32m[05/03 00:09:02 d2.evaluation.evaluator]: \u001b[0mInference done 4014/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:03:09\n",
            "\u001b[32m[05/03 00:09:07 d2.evaluation.evaluator]: \u001b[0mInference done 4061/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:03:04\n",
            "\u001b[32m[05/03 00:09:12 d2.evaluation.evaluator]: \u001b[0mInference done 4108/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:02:59\n",
            "\u001b[32m[05/03 00:09:17 d2.evaluation.evaluator]: \u001b[0mInference done 4156/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:02:54\n",
            "\u001b[32m[05/03 00:09:22 d2.evaluation.evaluator]: \u001b[0mInference done 4204/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:02:49\n",
            "\u001b[32m[05/03 00:09:27 d2.evaluation.evaluator]: \u001b[0mInference done 4251/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:02:44\n",
            "\u001b[32m[05/03 00:09:32 d2.evaluation.evaluator]: \u001b[0mInference done 4300/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:02:39\n",
            "\u001b[32m[05/03 00:09:37 d2.evaluation.evaluator]: \u001b[0mInference done 4348/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:02:34\n",
            "\u001b[32m[05/03 00:09:42 d2.evaluation.evaluator]: \u001b[0mInference done 4396/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:02:29\n",
            "\u001b[32m[05/03 00:09:47 d2.evaluation.evaluator]: \u001b[0mInference done 4444/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:02:24\n",
            "\u001b[32m[05/03 00:09:52 d2.evaluation.evaluator]: \u001b[0mInference done 4492/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:02:19\n",
            "\u001b[32m[05/03 00:09:57 d2.evaluation.evaluator]: \u001b[0mInference done 4539/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:02:14\n",
            "\u001b[32m[05/03 00:10:03 d2.evaluation.evaluator]: \u001b[0mInference done 4587/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:02:09\n",
            "\u001b[32m[05/03 00:10:08 d2.evaluation.evaluator]: \u001b[0mInference done 4635/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:02:04\n",
            "\u001b[32m[05/03 00:10:13 d2.evaluation.evaluator]: \u001b[0mInference done 4682/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:01:59\n",
            "\u001b[32m[05/03 00:10:18 d2.evaluation.evaluator]: \u001b[0mInference done 4730/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:01:54\n",
            "\u001b[32m[05/03 00:10:23 d2.evaluation.evaluator]: \u001b[0mInference done 4778/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:01:49\n",
            "\u001b[32m[05/03 00:10:28 d2.evaluation.evaluator]: \u001b[0mInference done 4826/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1049 s/iter. ETA=0:01:44\n",
            "\u001b[32m[05/03 00:10:33 d2.evaluation.evaluator]: \u001b[0mInference done 4874/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:01:39\n",
            "\u001b[32m[05/03 00:10:38 d2.evaluation.evaluator]: \u001b[0mInference done 4922/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1049 s/iter. ETA=0:01:34\n",
            "\u001b[32m[05/03 00:10:43 d2.evaluation.evaluator]: \u001b[0mInference done 4970/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1049 s/iter. ETA=0:01:29\n",
            "\u001b[32m[05/03 00:10:48 d2.evaluation.evaluator]: \u001b[0mInference done 5017/5823. Dataloading: 0.0016 s/iter. Inference: 0.1028 s/iter. Eval: 0.0004 s/iter. Total: 0.1049 s/iter. ETA=0:01:24\n",
            "\u001b[32m[05/03 00:10:53 d2.evaluation.evaluator]: \u001b[0mInference done 5064/5823. Dataloading: 0.0016 s/iter. Inference: 0.1028 s/iter. Eval: 0.0004 s/iter. Total: 0.1049 s/iter. ETA=0:01:19\n",
            "\u001b[32m[05/03 00:10:58 d2.evaluation.evaluator]: \u001b[0mInference done 5112/5823. Dataloading: 0.0016 s/iter. Inference: 0.1028 s/iter. Eval: 0.0004 s/iter. Total: 0.1049 s/iter. ETA=0:01:14\n",
            "\u001b[32m[05/03 00:11:03 d2.evaluation.evaluator]: \u001b[0mInference done 5160/5823. Dataloading: 0.0016 s/iter. Inference: 0.1028 s/iter. Eval: 0.0004 s/iter. Total: 0.1049 s/iter. ETA=0:01:09\n",
            "\u001b[32m[05/03 00:11:08 d2.evaluation.evaluator]: \u001b[0mInference done 5208/5823. Dataloading: 0.0016 s/iter. Inference: 0.1028 s/iter. Eval: 0.0004 s/iter. Total: 0.1049 s/iter. ETA=0:01:04\n",
            "\u001b[32m[05/03 00:11:13 d2.evaluation.evaluator]: \u001b[0mInference done 5255/5823. Dataloading: 0.0016 s/iter. Inference: 0.1028 s/iter. Eval: 0.0004 s/iter. Total: 0.1049 s/iter. ETA=0:00:59\n",
            "\u001b[32m[05/03 00:11:18 d2.evaluation.evaluator]: \u001b[0mInference done 5303/5823. Dataloading: 0.0016 s/iter. Inference: 0.1028 s/iter. Eval: 0.0004 s/iter. Total: 0.1049 s/iter. ETA=0:00:54\n",
            "\u001b[32m[05/03 00:11:23 d2.evaluation.evaluator]: \u001b[0mInference done 5350/5823. Dataloading: 0.0016 s/iter. Inference: 0.1028 s/iter. Eval: 0.0004 s/iter. Total: 0.1050 s/iter. ETA=0:00:49\n",
            "\u001b[32m[05/03 00:11:28 d2.evaluation.evaluator]: \u001b[0mInference done 5397/5823. Dataloading: 0.0016 s/iter. Inference: 0.1029 s/iter. Eval: 0.0004 s/iter. Total: 0.1050 s/iter. ETA=0:00:44\n",
            "\u001b[32m[05/03 00:11:33 d2.evaluation.evaluator]: \u001b[0mInference done 5445/5823. Dataloading: 0.0016 s/iter. Inference: 0.1029 s/iter. Eval: 0.0004 s/iter. Total: 0.1050 s/iter. ETA=0:00:39\n",
            "\u001b[32m[05/03 00:11:38 d2.evaluation.evaluator]: \u001b[0mInference done 5492/5823. Dataloading: 0.0016 s/iter. Inference: 0.1029 s/iter. Eval: 0.0004 s/iter. Total: 0.1050 s/iter. ETA=0:00:34\n",
            "\u001b[32m[05/03 00:11:43 d2.evaluation.evaluator]: \u001b[0mInference done 5541/5823. Dataloading: 0.0016 s/iter. Inference: 0.1029 s/iter. Eval: 0.0004 s/iter. Total: 0.1050 s/iter. ETA=0:00:29\n",
            "\u001b[32m[05/03 00:11:49 d2.evaluation.evaluator]: \u001b[0mInference done 5589/5823. Dataloading: 0.0016 s/iter. Inference: 0.1029 s/iter. Eval: 0.0004 s/iter. Total: 0.1050 s/iter. ETA=0:00:24\n",
            "\u001b[32m[05/03 00:11:54 d2.evaluation.evaluator]: \u001b[0mInference done 5637/5823. Dataloading: 0.0016 s/iter. Inference: 0.1029 s/iter. Eval: 0.0004 s/iter. Total: 0.1050 s/iter. ETA=0:00:19\n",
            "\u001b[32m[05/03 00:11:59 d2.evaluation.evaluator]: \u001b[0mInference done 5685/5823. Dataloading: 0.0016 s/iter. Inference: 0.1029 s/iter. Eval: 0.0004 s/iter. Total: 0.1050 s/iter. ETA=0:00:14\n",
            "\u001b[32m[05/03 00:12:04 d2.evaluation.evaluator]: \u001b[0mInference done 5734/5823. Dataloading: 0.0016 s/iter. Inference: 0.1029 s/iter. Eval: 0.0004 s/iter. Total: 0.1050 s/iter. ETA=0:00:09\n",
            "\u001b[32m[05/03 00:12:09 d2.evaluation.evaluator]: \u001b[0mInference done 5783/5823. Dataloading: 0.0016 s/iter. Inference: 0.1028 s/iter. Eval: 0.0004 s/iter. Total: 0.1050 s/iter. ETA=0:00:04\n",
            "\u001b[32m[05/03 00:12:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:10:10.713375 (0.104970 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/03 00:12:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:09:58 (0.102838 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/03 00:12:13 d2.evaluation.pascal_voc_evaluation]: \u001b[0mEvaluating voc_val using 2012 metric. Note that results do not use the official Matlab API.\n",
            "\u001b[32m[05/03 00:15:00 d2.engine.defaults]: \u001b[0mEvaluation results for voc_val in csv format:\n",
            "\u001b[32m[05/03 00:15:00 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/03 00:15:00 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75\n",
            "\u001b[32m[05/03 00:15:00 d2.evaluation.testing]: \u001b[0mcopypaste: 1.2506,4.4514,0.2192\n",
            "\u001b[32m[05/03 00:15:05 d2.engine.hooks]: \u001b[0mSaved first model at 4.45139 @ 357 steps\n",
            "\u001b[32m[05/03 00:15:07 d2.utils.events]: \u001b[0m eta: 1:43:01  iter: 359  total_loss: 0.4709  loss_cls: 0.2282  loss_box_reg: 0.1664  loss_rpn_cls: 0.04557  loss_rpn_loc: 0.02608    time: 0.8988  last_time: 0.8315  data_time: 0.0083  last_data_time: 0.0117   lr: 0.0008991  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:15:24 d2.utils.events]: \u001b[0m eta: 1:42:19  iter: 379  total_loss: 0.6609  loss_cls: 0.2928  loss_box_reg: 0.2436  loss_rpn_cls: 0.05316  loss_rpn_loc: 0.03301    time: 0.8973  last_time: 0.8344  data_time: 0.0080  last_data_time: 0.0027   lr: 0.00094905  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:15:42 d2.utils.events]: \u001b[0m eta: 1:41:47  iter: 399  total_loss: 0.4889  loss_cls: 0.2116  loss_box_reg: 0.1686  loss_rpn_cls: 0.03298  loss_rpn_loc: 0.02956    time: 0.8965  last_time: 0.9160  data_time: 0.0081  last_data_time: 0.0027   lr: 0.000999  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:16:01 d2.utils.events]: \u001b[0m eta: 1:41:32  iter: 419  total_loss: 0.5275  loss_cls: 0.2482  loss_box_reg: 0.1997  loss_rpn_cls: 0.03501  loss_rpn_loc: 0.03579    time: 0.8975  last_time: 0.9732  data_time: 0.0084  last_data_time: 0.0117   lr: 0.001049  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:16:19 d2.utils.events]: \u001b[0m eta: 1:40:59  iter: 439  total_loss: 0.5043  loss_cls: 0.2311  loss_box_reg: 0.1939  loss_rpn_cls: 0.03303  loss_rpn_loc: 0.03248    time: 0.8971  last_time: 0.8777  data_time: 0.0079  last_data_time: 0.0029   lr: 0.0010989  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:16:37 d2.utils.events]: \u001b[0m eta: 1:40:36  iter: 459  total_loss: 0.5636  loss_cls: 0.2431  loss_box_reg: 0.2173  loss_rpn_cls: 0.03954  loss_rpn_loc: 0.04745    time: 0.8968  last_time: 0.8680  data_time: 0.0081  last_data_time: 0.0088   lr: 0.0011489  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:16:55 d2.utils.events]: \u001b[0m eta: 1:40:07  iter: 479  total_loss: 0.5553  loss_cls: 0.2611  loss_box_reg: 0.2548  loss_rpn_cls: 0.03354  loss_rpn_loc: 0.03229    time: 0.8970  last_time: 0.8803  data_time: 0.0077  last_data_time: 0.0062   lr: 0.0011988  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:17:13 d2.utils.events]: \u001b[0m eta: 1:39:54  iter: 499  total_loss: 0.5204  loss_cls: 0.2401  loss_box_reg: 0.2109  loss_rpn_cls: 0.02896  loss_rpn_loc: 0.03176    time: 0.8966  last_time: 0.8659  data_time: 0.0081  last_data_time: 0.0096   lr: 0.0012488  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:17:31 d2.utils.events]: \u001b[0m eta: 1:39:36  iter: 519  total_loss: 0.5842  loss_cls: 0.2462  loss_box_reg: 0.2263  loss_rpn_cls: 0.03974  loss_rpn_loc: 0.04285    time: 0.8966  last_time: 0.8200  data_time: 0.0077  last_data_time: 0.0066   lr: 0.0012987  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:17:49 d2.utils.events]: \u001b[0m eta: 1:39:33  iter: 539  total_loss: 0.5017  loss_cls: 0.2332  loss_box_reg: 0.2077  loss_rpn_cls: 0.02061  loss_rpn_loc: 0.03505    time: 0.8982  last_time: 0.9329  data_time: 0.0082  last_data_time: 0.0126   lr: 0.0013487  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:18:08 d2.utils.events]: \u001b[0m eta: 1:39:25  iter: 559  total_loss: 0.4065  loss_cls: 0.1823  loss_box_reg: 0.189  loss_rpn_cls: 0.02494  loss_rpn_loc: 0.02687    time: 0.8994  last_time: 0.9070  data_time: 0.0080  last_data_time: 0.0084   lr: 0.0013986  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:18:27 d2.utils.events]: \u001b[0m eta: 1:39:22  iter: 579  total_loss: 0.5754  loss_cls: 0.2472  loss_box_reg: 0.2579  loss_rpn_cls: 0.0283  loss_rpn_loc: 0.03134    time: 0.9009  last_time: 1.0113  data_time: 0.0081  last_data_time: 0.0118   lr: 0.0014486  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:18:46 d2.utils.events]: \u001b[0m eta: 1:39:10  iter: 599  total_loss: 0.4694  loss_cls: 0.2246  loss_box_reg: 0.1939  loss_rpn_cls: 0.02517  loss_rpn_loc: 0.03388    time: 0.9015  last_time: 1.0059  data_time: 0.0079  last_data_time: 0.0082   lr: 0.0014985  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:19:04 d2.utils.events]: \u001b[0m eta: 1:38:53  iter: 619  total_loss: 0.5972  loss_cls: 0.2666  loss_box_reg: 0.2601  loss_rpn_cls: 0.03837  loss_rpn_loc: 0.03715    time: 0.9020  last_time: 0.9322  data_time: 0.0084  last_data_time: 0.0080   lr: 0.0015485  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:19:22 d2.utils.events]: \u001b[0m eta: 1:38:35  iter: 639  total_loss: 0.5293  loss_cls: 0.2234  loss_box_reg: 0.2092  loss_rpn_cls: 0.0285  loss_rpn_loc: 0.03005    time: 0.9021  last_time: 0.8212  data_time: 0.0079  last_data_time: 0.0111   lr: 0.0015984  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:19:41 d2.utils.events]: \u001b[0m eta: 1:38:21  iter: 659  total_loss: 0.4777  loss_cls: 0.1967  loss_box_reg: 0.2148  loss_rpn_cls: 0.02708  loss_rpn_loc: 0.02756    time: 0.9028  last_time: 0.9234  data_time: 0.0081  last_data_time: 0.0044   lr: 0.0016484  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:20:00 d2.utils.events]: \u001b[0m eta: 1:38:20  iter: 679  total_loss: 0.615  loss_cls: 0.2294  loss_box_reg: 0.3016  loss_rpn_cls: 0.02792  loss_rpn_loc: 0.0399    time: 0.9044  last_time: 0.8497  data_time: 0.0083  last_data_time: 0.0064   lr: 0.0016983  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:20:19 d2.utils.events]: \u001b[0m eta: 1:38:00  iter: 699  total_loss: 0.5279  loss_cls: 0.2132  loss_box_reg: 0.2301  loss_rpn_cls: 0.03099  loss_rpn_loc: 0.02986    time: 0.9046  last_time: 0.9393  data_time: 0.0084  last_data_time: 0.0054   lr: 0.0017483  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:22:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/03 00:22:01 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/03 00:22:01 d2.data.common]: \u001b[0mSerializing 5823 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/03 00:22:01 d2.data.common]: \u001b[0mSerialized dataset takes 2.67 MiB\n",
            "\u001b[32m[05/03 00:22:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 5823 batches\n",
            "\u001b[32m[05/03 00:22:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/5823. Dataloading: 0.0009 s/iter. Inference: 0.0985 s/iter. Eval: 0.0003 s/iter. Total: 0.0997 s/iter. ETA=0:09:39\n",
            "\u001b[32m[05/03 00:22:08 d2.evaluation.evaluator]: \u001b[0mInference done 62/5823. Dataloading: 0.0014 s/iter. Inference: 0.0979 s/iter. Eval: 0.0004 s/iter. Total: 0.0998 s/iter. ETA=0:09:35\n",
            "\u001b[32m[05/03 00:22:13 d2.evaluation.evaluator]: \u001b[0mInference done 111/5823. Dataloading: 0.0015 s/iter. Inference: 0.0995 s/iter. Eval: 0.0004 s/iter. Total: 0.1015 s/iter. ETA=0:09:39\n",
            "\u001b[32m[05/03 00:22:18 d2.evaluation.evaluator]: \u001b[0mInference done 161/5823. Dataloading: 0.0015 s/iter. Inference: 0.0995 s/iter. Eval: 0.0004 s/iter. Total: 0.1015 s/iter. ETA=0:09:34\n",
            "\u001b[32m[05/03 00:22:23 d2.evaluation.evaluator]: \u001b[0mInference done 210/5823. Dataloading: 0.0016 s/iter. Inference: 0.0999 s/iter. Eval: 0.0004 s/iter. Total: 0.1019 s/iter. ETA=0:09:31\n",
            "\u001b[32m[05/03 00:22:28 d2.evaluation.evaluator]: \u001b[0mInference done 260/5823. Dataloading: 0.0016 s/iter. Inference: 0.0998 s/iter. Eval: 0.0004 s/iter. Total: 0.1018 s/iter. ETA=0:09:26\n",
            "\u001b[32m[05/03 00:22:33 d2.evaluation.evaluator]: \u001b[0mInference done 310/5823. Dataloading: 0.0016 s/iter. Inference: 0.0997 s/iter. Eval: 0.0004 s/iter. Total: 0.1017 s/iter. ETA=0:09:20\n",
            "\u001b[32m[05/03 00:22:38 d2.evaluation.evaluator]: \u001b[0mInference done 360/5823. Dataloading: 0.0016 s/iter. Inference: 0.0997 s/iter. Eval: 0.0004 s/iter. Total: 0.1017 s/iter. ETA=0:09:15\n",
            "\u001b[32m[05/03 00:22:43 d2.evaluation.evaluator]: \u001b[0mInference done 409/5823. Dataloading: 0.0016 s/iter. Inference: 0.0999 s/iter. Eval: 0.0004 s/iter. Total: 0.1019 s/iter. ETA=0:09:11\n",
            "\u001b[32m[05/03 00:22:48 d2.evaluation.evaluator]: \u001b[0mInference done 458/5823. Dataloading: 0.0016 s/iter. Inference: 0.0999 s/iter. Eval: 0.0004 s/iter. Total: 0.1020 s/iter. ETA=0:09:07\n",
            "\u001b[32m[05/03 00:22:53 d2.evaluation.evaluator]: \u001b[0mInference done 508/5823. Dataloading: 0.0016 s/iter. Inference: 0.0999 s/iter. Eval: 0.0004 s/iter. Total: 0.1019 s/iter. ETA=0:09:01\n",
            "\u001b[32m[05/03 00:22:58 d2.evaluation.evaluator]: \u001b[0mInference done 556/5823. Dataloading: 0.0016 s/iter. Inference: 0.1001 s/iter. Eval: 0.0004 s/iter. Total: 0.1021 s/iter. ETA=0:08:57\n",
            "\u001b[32m[05/03 00:23:03 d2.evaluation.evaluator]: \u001b[0mInference done 605/5823. Dataloading: 0.0016 s/iter. Inference: 0.1002 s/iter. Eval: 0.0004 s/iter. Total: 0.1022 s/iter. ETA=0:08:53\n",
            "\u001b[32m[05/03 00:23:08 d2.evaluation.evaluator]: \u001b[0mInference done 654/5823. Dataloading: 0.0016 s/iter. Inference: 0.1002 s/iter. Eval: 0.0004 s/iter. Total: 0.1023 s/iter. ETA=0:08:48\n",
            "\u001b[32m[05/03 00:23:13 d2.evaluation.evaluator]: \u001b[0mInference done 703/5823. Dataloading: 0.0016 s/iter. Inference: 0.1003 s/iter. Eval: 0.0004 s/iter. Total: 0.1023 s/iter. ETA=0:08:43\n",
            "\u001b[32m[05/03 00:23:18 d2.evaluation.evaluator]: \u001b[0mInference done 752/5823. Dataloading: 0.0016 s/iter. Inference: 0.1003 s/iter. Eval: 0.0004 s/iter. Total: 0.1024 s/iter. ETA=0:08:39\n",
            "\u001b[32m[05/03 00:23:23 d2.evaluation.evaluator]: \u001b[0mInference done 800/5823. Dataloading: 0.0016 s/iter. Inference: 0.1005 s/iter. Eval: 0.0004 s/iter. Total: 0.1025 s/iter. ETA=0:08:34\n",
            "\u001b[32m[05/03 00:23:29 d2.evaluation.evaluator]: \u001b[0mInference done 850/5823. Dataloading: 0.0016 s/iter. Inference: 0.1004 s/iter. Eval: 0.0004 s/iter. Total: 0.1024 s/iter. ETA=0:08:29\n",
            "\u001b[32m[05/03 00:23:34 d2.evaluation.evaluator]: \u001b[0mInference done 900/5823. Dataloading: 0.0016 s/iter. Inference: 0.1003 s/iter. Eval: 0.0004 s/iter. Total: 0.1024 s/iter. ETA=0:08:24\n",
            "\u001b[32m[05/03 00:23:39 d2.evaluation.evaluator]: \u001b[0mInference done 949/5823. Dataloading: 0.0016 s/iter. Inference: 0.1004 s/iter. Eval: 0.0004 s/iter. Total: 0.1025 s/iter. ETA=0:08:19\n",
            "\u001b[32m[05/03 00:23:44 d2.evaluation.evaluator]: \u001b[0mInference done 998/5823. Dataloading: 0.0016 s/iter. Inference: 0.1005 s/iter. Eval: 0.0004 s/iter. Total: 0.1025 s/iter. ETA=0:08:14\n",
            "\u001b[32m[05/03 00:23:49 d2.evaluation.evaluator]: \u001b[0mInference done 1047/5823. Dataloading: 0.0016 s/iter. Inference: 0.1005 s/iter. Eval: 0.0004 s/iter. Total: 0.1026 s/iter. ETA=0:08:09\n",
            "\u001b[32m[05/03 00:23:54 d2.evaluation.evaluator]: \u001b[0mInference done 1097/5823. Dataloading: 0.0016 s/iter. Inference: 0.1005 s/iter. Eval: 0.0004 s/iter. Total: 0.1025 s/iter. ETA=0:08:04\n",
            "\u001b[32m[05/03 00:23:59 d2.evaluation.evaluator]: \u001b[0mInference done 1146/5823. Dataloading: 0.0016 s/iter. Inference: 0.1005 s/iter. Eval: 0.0004 s/iter. Total: 0.1025 s/iter. ETA=0:07:59\n",
            "\u001b[32m[05/03 00:24:04 d2.evaluation.evaluator]: \u001b[0mInference done 1195/5823. Dataloading: 0.0016 s/iter. Inference: 0.1005 s/iter. Eval: 0.0004 s/iter. Total: 0.1026 s/iter. ETA=0:07:54\n",
            "\u001b[32m[05/03 00:24:09 d2.evaluation.evaluator]: \u001b[0mInference done 1243/5823. Dataloading: 0.0016 s/iter. Inference: 0.1007 s/iter. Eval: 0.0004 s/iter. Total: 0.1027 s/iter. ETA=0:07:50\n",
            "\u001b[32m[05/03 00:24:14 d2.evaluation.evaluator]: \u001b[0mInference done 1291/5823. Dataloading: 0.0016 s/iter. Inference: 0.1007 s/iter. Eval: 0.0004 s/iter. Total: 0.1028 s/iter. ETA=0:07:45\n",
            "\u001b[32m[05/03 00:24:19 d2.evaluation.evaluator]: \u001b[0mInference done 1339/5823. Dataloading: 0.0016 s/iter. Inference: 0.1008 s/iter. Eval: 0.0004 s/iter. Total: 0.1029 s/iter. ETA=0:07:41\n",
            "\u001b[32m[05/03 00:24:24 d2.evaluation.evaluator]: \u001b[0mInference done 1387/5823. Dataloading: 0.0016 s/iter. Inference: 0.1009 s/iter. Eval: 0.0004 s/iter. Total: 0.1029 s/iter. ETA=0:07:36\n",
            "\u001b[32m[05/03 00:24:29 d2.evaluation.evaluator]: \u001b[0mInference done 1435/5823. Dataloading: 0.0016 s/iter. Inference: 0.1009 s/iter. Eval: 0.0004 s/iter. Total: 0.1030 s/iter. ETA=0:07:31\n",
            "\u001b[32m[05/03 00:24:34 d2.evaluation.evaluator]: \u001b[0mInference done 1483/5823. Dataloading: 0.0016 s/iter. Inference: 0.1010 s/iter. Eval: 0.0004 s/iter. Total: 0.1030 s/iter. ETA=0:07:27\n",
            "\u001b[32m[05/03 00:24:39 d2.evaluation.evaluator]: \u001b[0mInference done 1531/5823. Dataloading: 0.0016 s/iter. Inference: 0.1010 s/iter. Eval: 0.0004 s/iter. Total: 0.1031 s/iter. ETA=0:07:22\n",
            "\u001b[32m[05/03 00:24:44 d2.evaluation.evaluator]: \u001b[0mInference done 1579/5823. Dataloading: 0.0016 s/iter. Inference: 0.1011 s/iter. Eval: 0.0004 s/iter. Total: 0.1031 s/iter. ETA=0:07:17\n",
            "\u001b[32m[05/03 00:24:49 d2.evaluation.evaluator]: \u001b[0mInference done 1627/5823. Dataloading: 0.0016 s/iter. Inference: 0.1012 s/iter. Eval: 0.0004 s/iter. Total: 0.1032 s/iter. ETA=0:07:13\n",
            "\u001b[32m[05/03 00:24:55 d2.evaluation.evaluator]: \u001b[0mInference done 1676/5823. Dataloading: 0.0016 s/iter. Inference: 0.1012 s/iter. Eval: 0.0004 s/iter. Total: 0.1032 s/iter. ETA=0:07:08\n",
            "\u001b[32m[05/03 00:25:00 d2.evaluation.evaluator]: \u001b[0mInference done 1724/5823. Dataloading: 0.0016 s/iter. Inference: 0.1012 s/iter. Eval: 0.0004 s/iter. Total: 0.1033 s/iter. ETA=0:07:03\n",
            "\u001b[32m[05/03 00:25:05 d2.evaluation.evaluator]: \u001b[0mInference done 1773/5823. Dataloading: 0.0016 s/iter. Inference: 0.1012 s/iter. Eval: 0.0004 s/iter. Total: 0.1033 s/iter. ETA=0:06:58\n",
            "\u001b[32m[05/03 00:25:10 d2.evaluation.evaluator]: \u001b[0mInference done 1820/5823. Dataloading: 0.0016 s/iter. Inference: 0.1013 s/iter. Eval: 0.0004 s/iter. Total: 0.1034 s/iter. ETA=0:06:53\n",
            "\u001b[32m[05/03 00:25:15 d2.evaluation.evaluator]: \u001b[0mInference done 1869/5823. Dataloading: 0.0016 s/iter. Inference: 0.1014 s/iter. Eval: 0.0004 s/iter. Total: 0.1034 s/iter. ETA=0:06:48\n",
            "\u001b[32m[05/03 00:25:20 d2.evaluation.evaluator]: \u001b[0mInference done 1917/5823. Dataloading: 0.0016 s/iter. Inference: 0.1014 s/iter. Eval: 0.0004 s/iter. Total: 0.1035 s/iter. ETA=0:06:44\n",
            "\u001b[32m[05/03 00:25:25 d2.evaluation.evaluator]: \u001b[0mInference done 1965/5823. Dataloading: 0.0016 s/iter. Inference: 0.1014 s/iter. Eval: 0.0004 s/iter. Total: 0.1035 s/iter. ETA=0:06:39\n",
            "\u001b[32m[05/03 00:25:30 d2.evaluation.evaluator]: \u001b[0mInference done 2014/5823. Dataloading: 0.0016 s/iter. Inference: 0.1014 s/iter. Eval: 0.0004 s/iter. Total: 0.1035 s/iter. ETA=0:06:34\n",
            "\u001b[32m[05/03 00:25:35 d2.evaluation.evaluator]: \u001b[0mInference done 2062/5823. Dataloading: 0.0016 s/iter. Inference: 0.1015 s/iter. Eval: 0.0004 s/iter. Total: 0.1035 s/iter. ETA=0:06:29\n",
            "\u001b[32m[05/03 00:25:40 d2.evaluation.evaluator]: \u001b[0mInference done 2110/5823. Dataloading: 0.0016 s/iter. Inference: 0.1015 s/iter. Eval: 0.0004 s/iter. Total: 0.1035 s/iter. ETA=0:06:24\n",
            "\u001b[32m[05/03 00:25:45 d2.evaluation.evaluator]: \u001b[0mInference done 2158/5823. Dataloading: 0.0016 s/iter. Inference: 0.1015 s/iter. Eval: 0.0004 s/iter. Total: 0.1036 s/iter. ETA=0:06:19\n",
            "\u001b[32m[05/03 00:25:50 d2.evaluation.evaluator]: \u001b[0mInference done 2207/5823. Dataloading: 0.0016 s/iter. Inference: 0.1015 s/iter. Eval: 0.0004 s/iter. Total: 0.1036 s/iter. ETA=0:06:14\n",
            "\u001b[32m[05/03 00:25:55 d2.evaluation.evaluator]: \u001b[0mInference done 2255/5823. Dataloading: 0.0016 s/iter. Inference: 0.1016 s/iter. Eval: 0.0004 s/iter. Total: 0.1036 s/iter. ETA=0:06:09\n",
            "\u001b[32m[05/03 00:26:00 d2.evaluation.evaluator]: \u001b[0mInference done 2303/5823. Dataloading: 0.0016 s/iter. Inference: 0.1016 s/iter. Eval: 0.0004 s/iter. Total: 0.1037 s/iter. ETA=0:06:04\n",
            "\u001b[32m[05/03 00:26:05 d2.evaluation.evaluator]: \u001b[0mInference done 2351/5823. Dataloading: 0.0016 s/iter. Inference: 0.1016 s/iter. Eval: 0.0004 s/iter. Total: 0.1037 s/iter. ETA=0:06:00\n",
            "\u001b[32m[05/03 00:26:10 d2.evaluation.evaluator]: \u001b[0mInference done 2399/5823. Dataloading: 0.0016 s/iter. Inference: 0.1017 s/iter. Eval: 0.0004 s/iter. Total: 0.1037 s/iter. ETA=0:05:55\n",
            "\u001b[32m[05/03 00:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 2446/5823. Dataloading: 0.0016 s/iter. Inference: 0.1017 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:05:50\n",
            "\u001b[32m[05/03 00:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 2494/5823. Dataloading: 0.0016 s/iter. Inference: 0.1018 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:05:45\n",
            "\u001b[32m[05/03 00:26:25 d2.evaluation.evaluator]: \u001b[0mInference done 2542/5823. Dataloading: 0.0016 s/iter. Inference: 0.1018 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:05:40\n",
            "\u001b[32m[05/03 00:26:31 d2.evaluation.evaluator]: \u001b[0mInference done 2590/5823. Dataloading: 0.0016 s/iter. Inference: 0.1018 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:05:35\n",
            "\u001b[32m[05/03 00:26:36 d2.evaluation.evaluator]: \u001b[0mInference done 2637/5823. Dataloading: 0.0016 s/iter. Inference: 0.1019 s/iter. Eval: 0.0004 s/iter. Total: 0.1040 s/iter. ETA=0:05:31\n",
            "\u001b[32m[05/03 00:26:41 d2.evaluation.evaluator]: \u001b[0mInference done 2685/5823. Dataloading: 0.0016 s/iter. Inference: 0.1019 s/iter. Eval: 0.0004 s/iter. Total: 0.1040 s/iter. ETA=0:05:26\n",
            "\u001b[32m[05/03 00:26:46 d2.evaluation.evaluator]: \u001b[0mInference done 2733/5823. Dataloading: 0.0016 s/iter. Inference: 0.1020 s/iter. Eval: 0.0004 s/iter. Total: 0.1040 s/iter. ETA=0:05:21\n",
            "\u001b[32m[05/03 00:26:51 d2.evaluation.evaluator]: \u001b[0mInference done 2781/5823. Dataloading: 0.0016 s/iter. Inference: 0.1020 s/iter. Eval: 0.0004 s/iter. Total: 0.1040 s/iter. ETA=0:05:16\n",
            "\u001b[32m[05/03 00:26:56 d2.evaluation.evaluator]: \u001b[0mInference done 2829/5823. Dataloading: 0.0016 s/iter. Inference: 0.1020 s/iter. Eval: 0.0004 s/iter. Total: 0.1041 s/iter. ETA=0:05:11\n",
            "\u001b[32m[05/03 00:27:01 d2.evaluation.evaluator]: \u001b[0mInference done 2876/5823. Dataloading: 0.0016 s/iter. Inference: 0.1021 s/iter. Eval: 0.0004 s/iter. Total: 0.1041 s/iter. ETA=0:05:06\n",
            "\u001b[32m[05/03 00:27:06 d2.evaluation.evaluator]: \u001b[0mInference done 2923/5823. Dataloading: 0.0016 s/iter. Inference: 0.1021 s/iter. Eval: 0.0004 s/iter. Total: 0.1042 s/iter. ETA=0:05:02\n",
            "\u001b[32m[05/03 00:27:11 d2.evaluation.evaluator]: \u001b[0mInference done 2970/5823. Dataloading: 0.0016 s/iter. Inference: 0.1021 s/iter. Eval: 0.0004 s/iter. Total: 0.1042 s/iter. ETA=0:04:57\n",
            "\u001b[32m[05/03 00:27:16 d2.evaluation.evaluator]: \u001b[0mInference done 3017/5823. Dataloading: 0.0016 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1042 s/iter. ETA=0:04:52\n",
            "\u001b[32m[05/03 00:27:21 d2.evaluation.evaluator]: \u001b[0mInference done 3065/5823. Dataloading: 0.0016 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1043 s/iter. ETA=0:04:47\n",
            "\u001b[32m[05/03 00:27:26 d2.evaluation.evaluator]: \u001b[0mInference done 3113/5823. Dataloading: 0.0016 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1043 s/iter. ETA=0:04:42\n",
            "\u001b[32m[05/03 00:27:31 d2.evaluation.evaluator]: \u001b[0mInference done 3160/5823. Dataloading: 0.0016 s/iter. Inference: 0.1023 s/iter. Eval: 0.0004 s/iter. Total: 0.1043 s/iter. ETA=0:04:37\n",
            "\u001b[32m[05/03 00:27:36 d2.evaluation.evaluator]: \u001b[0mInference done 3208/5823. Dataloading: 0.0016 s/iter. Inference: 0.1023 s/iter. Eval: 0.0004 s/iter. Total: 0.1044 s/iter. ETA=0:04:32\n",
            "\u001b[32m[05/03 00:27:41 d2.evaluation.evaluator]: \u001b[0mInference done 3256/5823. Dataloading: 0.0016 s/iter. Inference: 0.1023 s/iter. Eval: 0.0004 s/iter. Total: 0.1044 s/iter. ETA=0:04:27\n",
            "\u001b[32m[05/03 00:27:46 d2.evaluation.evaluator]: \u001b[0mInference done 3303/5823. Dataloading: 0.0016 s/iter. Inference: 0.1023 s/iter. Eval: 0.0004 s/iter. Total: 0.1044 s/iter. ETA=0:04:23\n",
            "\u001b[32m[05/03 00:27:51 d2.evaluation.evaluator]: \u001b[0mInference done 3351/5823. Dataloading: 0.0016 s/iter. Inference: 0.1024 s/iter. Eval: 0.0004 s/iter. Total: 0.1044 s/iter. ETA=0:04:18\n",
            "\u001b[32m[05/03 00:27:56 d2.evaluation.evaluator]: \u001b[0mInference done 3398/5823. Dataloading: 0.0016 s/iter. Inference: 0.1024 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:04:13\n",
            "\u001b[32m[05/03 00:28:02 d2.evaluation.evaluator]: \u001b[0mInference done 3446/5823. Dataloading: 0.0016 s/iter. Inference: 0.1024 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:04:08\n",
            "\u001b[32m[05/03 00:28:07 d2.evaluation.evaluator]: \u001b[0mInference done 3493/5823. Dataloading: 0.0016 s/iter. Inference: 0.1024 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:04:03\n",
            "\u001b[32m[05/03 00:28:12 d2.evaluation.evaluator]: \u001b[0mInference done 3541/5823. Dataloading: 0.0016 s/iter. Inference: 0.1024 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:03:58\n",
            "\u001b[32m[05/03 00:28:17 d2.evaluation.evaluator]: \u001b[0mInference done 3589/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:03:53\n",
            "\u001b[32m[05/03 00:28:22 d2.evaluation.evaluator]: \u001b[0mInference done 3637/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:03:48\n",
            "\u001b[32m[05/03 00:28:27 d2.evaluation.evaluator]: \u001b[0mInference done 3686/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:03:43\n",
            "\u001b[32m[05/03 00:28:32 d2.evaluation.evaluator]: \u001b[0mInference done 3734/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:03:38\n",
            "\u001b[32m[05/03 00:28:37 d2.evaluation.evaluator]: \u001b[0mInference done 3782/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:03:33\n",
            "\u001b[32m[05/03 00:28:42 d2.evaluation.evaluator]: \u001b[0mInference done 3831/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:03:28\n",
            "\u001b[32m[05/03 00:28:47 d2.evaluation.evaluator]: \u001b[0mInference done 3879/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:03:23\n",
            "\u001b[32m[05/03 00:28:52 d2.evaluation.evaluator]: \u001b[0mInference done 3927/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:03:18\n",
            "\u001b[32m[05/03 00:28:57 d2.evaluation.evaluator]: \u001b[0mInference done 3976/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:03:13\n",
            "\u001b[32m[05/03 00:29:02 d2.evaluation.evaluator]: \u001b[0mInference done 4024/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:03:08\n",
            "\u001b[32m[05/03 00:29:07 d2.evaluation.evaluator]: \u001b[0mInference done 4072/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:03:03\n",
            "\u001b[32m[05/03 00:29:12 d2.evaluation.evaluator]: \u001b[0mInference done 4119/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:02:58\n",
            "\u001b[32m[05/03 00:29:17 d2.evaluation.evaluator]: \u001b[0mInference done 4167/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:02:53\n",
            "\u001b[32m[05/03 00:29:22 d2.evaluation.evaluator]: \u001b[0mInference done 4215/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:02:48\n",
            "\u001b[32m[05/03 00:29:27 d2.evaluation.evaluator]: \u001b[0mInference done 4262/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:02:43\n",
            "\u001b[32m[05/03 00:29:32 d2.evaluation.evaluator]: \u001b[0mInference done 4311/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:02:38\n",
            "\u001b[32m[05/03 00:29:37 d2.evaluation.evaluator]: \u001b[0mInference done 4359/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:02:33\n",
            "\u001b[32m[05/03 00:29:42 d2.evaluation.evaluator]: \u001b[0mInference done 4407/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:02:28\n",
            "\u001b[32m[05/03 00:29:47 d2.evaluation.evaluator]: \u001b[0mInference done 4455/5823. Dataloading: 0.0016 s/iter. Inference: 0.1025 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:02:23\n",
            "\u001b[32m[05/03 00:29:53 d2.evaluation.evaluator]: \u001b[0mInference done 4503/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:02:18\n",
            "\u001b[32m[05/03 00:29:58 d2.evaluation.evaluator]: \u001b[0mInference done 4550/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:02:13\n",
            "\u001b[32m[05/03 00:30:03 d2.evaluation.evaluator]: \u001b[0mInference done 4598/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:02:08\n",
            "\u001b[32m[05/03 00:30:08 d2.evaluation.evaluator]: \u001b[0mInference done 4646/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:02:03\n",
            "\u001b[32m[05/03 00:30:13 d2.evaluation.evaluator]: \u001b[0mInference done 4694/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:01:58\n",
            "\u001b[32m[05/03 00:30:18 d2.evaluation.evaluator]: \u001b[0mInference done 4742/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:01:53\n",
            "\u001b[32m[05/03 00:30:23 d2.evaluation.evaluator]: \u001b[0mInference done 4790/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:01:48\n",
            "\u001b[32m[05/03 00:30:28 d2.evaluation.evaluator]: \u001b[0mInference done 4838/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:01:43\n",
            "\u001b[32m[05/03 00:30:33 d2.evaluation.evaluator]: \u001b[0mInference done 4887/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:01:37\n",
            "\u001b[32m[05/03 00:30:38 d2.evaluation.evaluator]: \u001b[0mInference done 4934/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:01:33\n",
            "\u001b[32m[05/03 00:30:43 d2.evaluation.evaluator]: \u001b[0mInference done 4982/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:01:28\n",
            "\u001b[32m[05/03 00:30:48 d2.evaluation.evaluator]: \u001b[0mInference done 5030/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:01:23\n",
            "\u001b[32m[05/03 00:30:53 d2.evaluation.evaluator]: \u001b[0mInference done 5077/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:01:18\n",
            "\u001b[32m[05/03 00:30:58 d2.evaluation.evaluator]: \u001b[0mInference done 5125/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:01:13\n",
            "\u001b[32m[05/03 00:31:03 d2.evaluation.evaluator]: \u001b[0mInference done 5173/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:01:08\n",
            "\u001b[32m[05/03 00:31:08 d2.evaluation.evaluator]: \u001b[0mInference done 5221/5823. Dataloading: 0.0016 s/iter. Inference: 0.1026 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:01:03\n",
            "\u001b[32m[05/03 00:31:13 d2.evaluation.evaluator]: \u001b[0mInference done 5268/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:00:58\n",
            "\u001b[32m[05/03 00:31:18 d2.evaluation.evaluator]: \u001b[0mInference done 5316/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:00:53\n",
            "\u001b[32m[05/03 00:31:23 d2.evaluation.evaluator]: \u001b[0mInference done 5364/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:00:48\n",
            "\u001b[32m[05/03 00:31:28 d2.evaluation.evaluator]: \u001b[0mInference done 5412/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:00:43\n",
            "\u001b[32m[05/03 00:31:34 d2.evaluation.evaluator]: \u001b[0mInference done 5460/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:00:38\n",
            "\u001b[32m[05/03 00:31:39 d2.evaluation.evaluator]: \u001b[0mInference done 5509/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:00:32\n",
            "\u001b[32m[05/03 00:31:44 d2.evaluation.evaluator]: \u001b[0mInference done 5558/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:00:27\n",
            "\u001b[32m[05/03 00:31:49 d2.evaluation.evaluator]: \u001b[0mInference done 5606/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:00:22\n",
            "\u001b[32m[05/03 00:31:54 d2.evaluation.evaluator]: \u001b[0mInference done 5654/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:00:17\n",
            "\u001b[32m[05/03 00:31:59 d2.evaluation.evaluator]: \u001b[0mInference done 5703/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:00:12\n",
            "\u001b[32m[05/03 00:32:04 d2.evaluation.evaluator]: \u001b[0mInference done 5752/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:00:07\n",
            "\u001b[32m[05/03 00:32:09 d2.evaluation.evaluator]: \u001b[0mInference done 5800/5823. Dataloading: 0.0016 s/iter. Inference: 0.1027 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:00:02\n",
            "\u001b[32m[05/03 00:32:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:10:09.469824 (0.104756 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/03 00:32:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:09:57 (0.102670 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/03 00:32:11 d2.evaluation.pascal_voc_evaluation]: \u001b[0mEvaluating voc_val using 2012 metric. Note that results do not use the official Matlab API.\n",
            "\u001b[32m[05/03 00:33:04 d2.engine.defaults]: \u001b[0mEvaluation results for voc_val in csv format:\n",
            "\u001b[32m[05/03 00:33:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/03 00:33:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75\n",
            "\u001b[32m[05/03 00:33:04 d2.evaluation.testing]: \u001b[0mcopypaste: 14.2325,38.1895,5.5192\n",
            "\u001b[32m[05/03 00:33:40 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for bbox/AP50 is 38.18954, better than last best score 4.45139 @ iteration 357.\n",
            "\u001b[32m[05/03 00:33:43 d2.utils.events]: \u001b[0m eta: 1:37:45  iter: 719  total_loss: 0.5134  loss_cls: 0.1879  loss_box_reg: 0.232  loss_rpn_cls: 0.02025  loss_rpn_loc: 0.03592    time: 0.9048  last_time: 1.0394  data_time: 0.0079  last_data_time: 0.0082   lr: 0.0017982  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:34:01 d2.utils.events]: \u001b[0m eta: 1:37:23  iter: 739  total_loss: 0.5519  loss_cls: 0.2085  loss_box_reg: 0.2571  loss_rpn_cls: 0.02541  loss_rpn_loc: 0.03373    time: 0.9043  last_time: 0.9772  data_time: 0.0083  last_data_time: 0.0098   lr: 0.0018482  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:34:19 d2.utils.events]: \u001b[0m eta: 1:36:55  iter: 759  total_loss: 0.5265  loss_cls: 0.2063  loss_box_reg: 0.2407  loss_rpn_cls: 0.02352  loss_rpn_loc: 0.03171    time: 0.9037  last_time: 0.8034  data_time: 0.0082  last_data_time: 0.0122   lr: 0.0018981  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:34:37 d2.utils.events]: \u001b[0m eta: 1:36:33  iter: 779  total_loss: 0.4993  loss_cls: 0.1898  loss_box_reg: 0.2491  loss_rpn_cls: 0.02404  loss_rpn_loc: 0.03346    time: 0.9033  last_time: 0.9192  data_time: 0.0083  last_data_time: 0.0106   lr: 0.0019481  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:34:56 d2.utils.events]: \u001b[0m eta: 1:36:27  iter: 799  total_loss: 0.5521  loss_cls: 0.199  loss_box_reg: 0.2828  loss_rpn_cls: 0.02891  loss_rpn_loc: 0.03439    time: 0.9038  last_time: 0.7421  data_time: 0.0078  last_data_time: 0.0063   lr: 0.001998  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:35:14 d2.utils.events]: \u001b[0m eta: 1:36:12  iter: 819  total_loss: 0.6247  loss_cls: 0.2428  loss_box_reg: 0.2987  loss_rpn_cls: 0.02388  loss_rpn_loc: 0.03875    time: 0.9045  last_time: 0.9539  data_time: 0.0082  last_data_time: 0.0121   lr: 0.002048  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:35:33 d2.utils.events]: \u001b[0m eta: 1:35:57  iter: 839  total_loss: 0.594  loss_cls: 0.2271  loss_box_reg: 0.3046  loss_rpn_cls: 0.02304  loss_rpn_loc: 0.02851    time: 0.9048  last_time: 0.8127  data_time: 0.0080  last_data_time: 0.0102   lr: 0.0020979  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:35:51 d2.utils.events]: \u001b[0m eta: 1:35:39  iter: 859  total_loss: 0.4878  loss_cls: 0.1986  loss_box_reg: 0.2085  loss_rpn_cls: 0.02623  loss_rpn_loc: 0.03436    time: 0.9051  last_time: 0.8430  data_time: 0.0078  last_data_time: 0.0054   lr: 0.0021479  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:36:10 d2.utils.events]: \u001b[0m eta: 1:35:21  iter: 879  total_loss: 0.5188  loss_cls: 0.2011  loss_box_reg: 0.2634  loss_rpn_cls: 0.02303  loss_rpn_loc: 0.04051    time: 0.9052  last_time: 0.9096  data_time: 0.0081  last_data_time: 0.0079   lr: 0.0021978  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:36:29 d2.utils.events]: \u001b[0m eta: 1:35:08  iter: 899  total_loss: 0.5207  loss_cls: 0.2117  loss_box_reg: 0.2407  loss_rpn_cls: 0.03119  loss_rpn_loc: 0.03168    time: 0.9060  last_time: 0.9324  data_time: 0.0081  last_data_time: 0.0098   lr: 0.0022478  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:36:47 d2.utils.events]: \u001b[0m eta: 1:34:48  iter: 919  total_loss: 0.3946  loss_cls: 0.1799  loss_box_reg: 0.1687  loss_rpn_cls: 0.0176  loss_rpn_loc: 0.02743    time: 0.9062  last_time: 0.9201  data_time: 0.0081  last_data_time: 0.0080   lr: 0.0022977  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:37:05 d2.utils.events]: \u001b[0m eta: 1:34:30  iter: 939  total_loss: 0.3589  loss_cls: 0.1519  loss_box_reg: 0.1687  loss_rpn_cls: 0.01904  loss_rpn_loc: 0.02712    time: 0.9061  last_time: 0.9173  data_time: 0.0080  last_data_time: 0.0028   lr: 0.0023477  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:37:24 d2.utils.events]: \u001b[0m eta: 1:34:12  iter: 959  total_loss: 0.4995  loss_cls: 0.198  loss_box_reg: 0.247  loss_rpn_cls: 0.02456  loss_rpn_loc: 0.03036    time: 0.9064  last_time: 1.0030  data_time: 0.0081  last_data_time: 0.0109   lr: 0.0023976  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:37:42 d2.utils.events]: \u001b[0m eta: 1:33:53  iter: 979  total_loss: 0.5167  loss_cls: 0.2154  loss_box_reg: 0.2191  loss_rpn_cls: 0.02617  loss_rpn_loc: 0.03036    time: 0.9065  last_time: 0.7386  data_time: 0.0081  last_data_time: 0.0091   lr: 0.0024476  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:38:01 d2.utils.events]: \u001b[0m eta: 1:33:35  iter: 999  total_loss: 0.457  loss_cls: 0.1946  loss_box_reg: 0.2135  loss_rpn_cls: 0.02105  loss_rpn_loc: 0.02533    time: 0.9066  last_time: 0.8876  data_time: 0.0081  last_data_time: 0.0118   lr: 0.0024975  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:38:19 d2.utils.events]: \u001b[0m eta: 1:33:24  iter: 1019  total_loss: 0.3533  loss_cls: 0.1374  loss_box_reg: 0.1604  loss_rpn_cls: 0.01856  loss_rpn_loc: 0.02544    time: 0.9070  last_time: 0.8892  data_time: 0.0083  last_data_time: 0.0079   lr: 0.0025  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:38:37 d2.utils.events]: \u001b[0m eta: 1:33:06  iter: 1039  total_loss: 0.5318  loss_cls: 0.2002  loss_box_reg: 0.2455  loss_rpn_cls: 0.02521  loss_rpn_loc: 0.02518    time: 0.9066  last_time: 0.7788  data_time: 0.0079  last_data_time: 0.0049   lr: 0.0025  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:38:55 d2.utils.events]: \u001b[0m eta: 1:32:49  iter: 1059  total_loss: 0.549  loss_cls: 0.206  loss_box_reg: 0.245  loss_rpn_cls: 0.02389  loss_rpn_loc: 0.02428    time: 0.9067  last_time: 1.0096  data_time: 0.0082  last_data_time: 0.0092   lr: 0.0025  max_mem: 4874M\n",
            "\u001b[32m[05/03 00:40:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[05/03 00:40:46 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[05/03 00:40:46 d2.data.common]: \u001b[0mSerializing 5823 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/03 00:40:46 d2.data.common]: \u001b[0mSerialized dataset takes 2.67 MiB\n",
            "\u001b[32m[05/03 00:40:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 5823 batches\n",
            "\u001b[32m[05/03 00:40:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/5823. Dataloading: 0.0015 s/iter. Inference: 0.0970 s/iter. Eval: 0.0003 s/iter. Total: 0.0988 s/iter. ETA=0:09:34\n",
            "\u001b[32m[05/03 00:40:53 d2.evaluation.evaluator]: \u001b[0mInference done 62/5823. Dataloading: 0.0015 s/iter. Inference: 0.0975 s/iter. Eval: 0.0003 s/iter. Total: 0.0995 s/iter. ETA=0:09:33\n",
            "\u001b[32m[05/03 00:40:58 d2.evaluation.evaluator]: \u001b[0mInference done 111/5823. Dataloading: 0.0016 s/iter. Inference: 0.0990 s/iter. Eval: 0.0003 s/iter. Total: 0.1010 s/iter. ETA=0:09:37\n",
            "\u001b[32m[05/03 00:41:03 d2.evaluation.evaluator]: \u001b[0mInference done 161/5823. Dataloading: 0.0016 s/iter. Inference: 0.0990 s/iter. Eval: 0.0003 s/iter. Total: 0.1010 s/iter. ETA=0:09:31\n",
            "\u001b[32m[05/03 00:41:08 d2.evaluation.evaluator]: \u001b[0mInference done 210/5823. Dataloading: 0.0016 s/iter. Inference: 0.0994 s/iter. Eval: 0.0003 s/iter. Total: 0.1014 s/iter. ETA=0:09:28\n",
            "\u001b[32m[05/03 00:41:13 d2.evaluation.evaluator]: \u001b[0mInference done 260/5823. Dataloading: 0.0016 s/iter. Inference: 0.0993 s/iter. Eval: 0.0003 s/iter. Total: 0.1013 s/iter. ETA=0:09:23\n",
            "\u001b[32m[05/03 00:41:18 d2.evaluation.evaluator]: \u001b[0mInference done 310/5823. Dataloading: 0.0016 s/iter. Inference: 0.0993 s/iter. Eval: 0.0003 s/iter. Total: 0.1013 s/iter. ETA=0:09:18\n",
            "\u001b[32m[05/03 00:41:23 d2.evaluation.evaluator]: \u001b[0mInference done 360/5823. Dataloading: 0.0016 s/iter. Inference: 0.0993 s/iter. Eval: 0.0003 s/iter. Total: 0.1013 s/iter. ETA=0:09:13\n",
            "\u001b[32m[05/03 00:41:28 d2.evaluation.evaluator]: \u001b[0mInference done 409/5823. Dataloading: 0.0016 s/iter. Inference: 0.0996 s/iter. Eval: 0.0003 s/iter. Total: 0.1016 s/iter. ETA=0:09:09\n",
            "\u001b[32m[05/03 00:41:33 d2.evaluation.evaluator]: \u001b[0mInference done 458/5823. Dataloading: 0.0016 s/iter. Inference: 0.0997 s/iter. Eval: 0.0003 s/iter. Total: 0.1017 s/iter. ETA=0:09:05\n",
            "\u001b[32m[05/03 00:41:38 d2.evaluation.evaluator]: \u001b[0mInference done 508/5823. Dataloading: 0.0016 s/iter. Inference: 0.0996 s/iter. Eval: 0.0003 s/iter. Total: 0.1016 s/iter. ETA=0:09:00\n",
            "\u001b[32m[05/03 00:41:43 d2.evaluation.evaluator]: \u001b[0mInference done 557/5823. Dataloading: 0.0016 s/iter. Inference: 0.0998 s/iter. Eval: 0.0003 s/iter. Total: 0.1018 s/iter. ETA=0:08:55\n",
            "\u001b[32m[05/03 00:41:48 d2.evaluation.evaluator]: \u001b[0mInference done 606/5823. Dataloading: 0.0016 s/iter. Inference: 0.0999 s/iter. Eval: 0.0003 s/iter. Total: 0.1019 s/iter. ETA=0:08:51\n",
            "\u001b[32m[05/03 00:41:53 d2.evaluation.evaluator]: \u001b[0mInference done 655/5823. Dataloading: 0.0016 s/iter. Inference: 0.0999 s/iter. Eval: 0.0003 s/iter. Total: 0.1019 s/iter. ETA=0:08:46\n",
            "\u001b[32m[05/03 00:41:58 d2.evaluation.evaluator]: \u001b[0mInference done 705/5823. Dataloading: 0.0016 s/iter. Inference: 0.0999 s/iter. Eval: 0.0003 s/iter. Total: 0.1019 s/iter. ETA=0:08:41\n",
            "\u001b[32m[05/03 00:42:03 d2.evaluation.evaluator]: \u001b[0mInference done 754/5823. Dataloading: 0.0016 s/iter. Inference: 0.1000 s/iter. Eval: 0.0003 s/iter. Total: 0.1020 s/iter. ETA=0:08:36\n",
            "\u001b[32m[05/03 00:42:09 d2.evaluation.evaluator]: \u001b[0mInference done 803/5823. Dataloading: 0.0016 s/iter. Inference: 0.1001 s/iter. Eval: 0.0003 s/iter. Total: 0.1021 s/iter. ETA=0:08:32\n",
            "\u001b[32m[05/03 00:42:14 d2.evaluation.evaluator]: \u001b[0mInference done 853/5823. Dataloading: 0.0016 s/iter. Inference: 0.1000 s/iter. Eval: 0.0003 s/iter. Total: 0.1020 s/iter. ETA=0:08:27\n",
            "\u001b[32m[05/03 00:42:19 d2.evaluation.evaluator]: \u001b[0mInference done 903/5823. Dataloading: 0.0016 s/iter. Inference: 0.1000 s/iter. Eval: 0.0003 s/iter. Total: 0.1020 s/iter. ETA=0:08:21\n",
            "\u001b[32m[05/03 00:42:24 d2.evaluation.evaluator]: \u001b[0mInference done 952/5823. Dataloading: 0.0016 s/iter. Inference: 0.1000 s/iter. Eval: 0.0003 s/iter. Total: 0.1021 s/iter. ETA=0:08:17\n",
            "\u001b[32m[05/03 00:42:29 d2.evaluation.evaluator]: \u001b[0mInference done 1001/5823. Dataloading: 0.0016 s/iter. Inference: 0.1001 s/iter. Eval: 0.0003 s/iter. Total: 0.1021 s/iter. ETA=0:08:12\n",
            "\u001b[32m[05/03 00:42:34 d2.evaluation.evaluator]: \u001b[0mInference done 1050/5823. Dataloading: 0.0016 s/iter. Inference: 0.1002 s/iter. Eval: 0.0003 s/iter. Total: 0.1022 s/iter. ETA=0:08:07\n",
            "\u001b[32m[05/03 00:42:39 d2.evaluation.evaluator]: \u001b[0mInference done 1100/5823. Dataloading: 0.0016 s/iter. Inference: 0.1001 s/iter. Eval: 0.0003 s/iter. Total: 0.1021 s/iter. ETA=0:08:02\n",
            "\u001b[32m[05/03 00:42:44 d2.evaluation.evaluator]: \u001b[0mInference done 1149/5823. Dataloading: 0.0016 s/iter. Inference: 0.1001 s/iter. Eval: 0.0003 s/iter. Total: 0.1022 s/iter. ETA=0:07:57\n",
            "\u001b[32m[05/03 00:42:49 d2.evaluation.evaluator]: \u001b[0mInference done 1198/5823. Dataloading: 0.0016 s/iter. Inference: 0.1002 s/iter. Eval: 0.0003 s/iter. Total: 0.1022 s/iter. ETA=0:07:52\n",
            "\u001b[32m[05/03 00:42:54 d2.evaluation.evaluator]: \u001b[0mInference done 1246/5823. Dataloading: 0.0016 s/iter. Inference: 0.1003 s/iter. Eval: 0.0003 s/iter. Total: 0.1023 s/iter. ETA=0:07:48\n",
            "\u001b[32m[05/03 00:42:59 d2.evaluation.evaluator]: \u001b[0mInference done 1295/5823. Dataloading: 0.0016 s/iter. Inference: 0.1003 s/iter. Eval: 0.0003 s/iter. Total: 0.1024 s/iter. ETA=0:07:43\n",
            "\u001b[32m[05/03 00:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 1343/5823. Dataloading: 0.0016 s/iter. Inference: 0.1004 s/iter. Eval: 0.0003 s/iter. Total: 0.1024 s/iter. ETA=0:07:38\n",
            "\u001b[32m[05/03 00:43:09 d2.evaluation.evaluator]: \u001b[0mInference done 1391/5823. Dataloading: 0.0016 s/iter. Inference: 0.1005 s/iter. Eval: 0.0003 s/iter. Total: 0.1025 s/iter. ETA=0:07:34\n",
            "\u001b[32m[05/03 00:43:14 d2.evaluation.evaluator]: \u001b[0mInference done 1439/5823. Dataloading: 0.0016 s/iter. Inference: 0.1006 s/iter. Eval: 0.0003 s/iter. Total: 0.1026 s/iter. ETA=0:07:29\n",
            "\u001b[32m[05/03 00:43:19 d2.evaluation.evaluator]: \u001b[0mInference done 1487/5823. Dataloading: 0.0016 s/iter. Inference: 0.1006 s/iter. Eval: 0.0003 s/iter. Total: 0.1027 s/iter. ETA=0:07:25\n",
            "\u001b[32m[05/03 00:43:24 d2.evaluation.evaluator]: \u001b[0mInference done 1536/5823. Dataloading: 0.0016 s/iter. Inference: 0.1007 s/iter. Eval: 0.0003 s/iter. Total: 0.1027 s/iter. ETA=0:07:20\n",
            "\u001b[32m[05/03 00:43:29 d2.evaluation.evaluator]: \u001b[0mInference done 1584/5823. Dataloading: 0.0016 s/iter. Inference: 0.1007 s/iter. Eval: 0.0003 s/iter. Total: 0.1028 s/iter. ETA=0:07:15\n",
            "\u001b[32m[05/03 00:43:34 d2.evaluation.evaluator]: \u001b[0mInference done 1632/5823. Dataloading: 0.0016 s/iter. Inference: 0.1008 s/iter. Eval: 0.0003 s/iter. Total: 0.1028 s/iter. ETA=0:07:10\n",
            "\u001b[32m[05/03 00:43:39 d2.evaluation.evaluator]: \u001b[0mInference done 1680/5823. Dataloading: 0.0016 s/iter. Inference: 0.1008 s/iter. Eval: 0.0003 s/iter. Total: 0.1029 s/iter. ETA=0:07:06\n",
            "\u001b[32m[05/03 00:43:44 d2.evaluation.evaluator]: \u001b[0mInference done 1728/5823. Dataloading: 0.0016 s/iter. Inference: 0.1009 s/iter. Eval: 0.0003 s/iter. Total: 0.1029 s/iter. ETA=0:07:01\n",
            "\u001b[32m[05/03 00:43:49 d2.evaluation.evaluator]: \u001b[0mInference done 1777/5823. Dataloading: 0.0016 s/iter. Inference: 0.1009 s/iter. Eval: 0.0003 s/iter. Total: 0.1030 s/iter. ETA=0:06:56\n",
            "\u001b[32m[05/03 00:43:55 d2.evaluation.evaluator]: \u001b[0mInference done 1824/5823. Dataloading: 0.0016 s/iter. Inference: 0.1010 s/iter. Eval: 0.0003 s/iter. Total: 0.1031 s/iter. ETA=0:06:52\n",
            "\u001b[32m[05/03 00:44:00 d2.evaluation.evaluator]: \u001b[0mInference done 1873/5823. Dataloading: 0.0016 s/iter. Inference: 0.1010 s/iter. Eval: 0.0003 s/iter. Total: 0.1031 s/iter. ETA=0:06:47\n",
            "\u001b[32m[05/03 00:44:05 d2.evaluation.evaluator]: \u001b[0mInference done 1921/5823. Dataloading: 0.0016 s/iter. Inference: 0.1011 s/iter. Eval: 0.0003 s/iter. Total: 0.1031 s/iter. ETA=0:06:42\n",
            "\u001b[32m[05/03 00:44:10 d2.evaluation.evaluator]: \u001b[0mInference done 1969/5823. Dataloading: 0.0016 s/iter. Inference: 0.1011 s/iter. Eval: 0.0003 s/iter. Total: 0.1031 s/iter. ETA=0:06:37\n",
            "\u001b[32m[05/03 00:44:15 d2.evaluation.evaluator]: \u001b[0mInference done 2018/5823. Dataloading: 0.0016 s/iter. Inference: 0.1011 s/iter. Eval: 0.0003 s/iter. Total: 0.1031 s/iter. ETA=0:06:32\n",
            "\u001b[32m[05/03 00:44:20 d2.evaluation.evaluator]: \u001b[0mInference done 2066/5823. Dataloading: 0.0016 s/iter. Inference: 0.1011 s/iter. Eval: 0.0003 s/iter. Total: 0.1032 s/iter. ETA=0:06:27\n",
            "\u001b[32m[05/03 00:44:25 d2.evaluation.evaluator]: \u001b[0mInference done 2114/5823. Dataloading: 0.0016 s/iter. Inference: 0.1012 s/iter. Eval: 0.0003 s/iter. Total: 0.1032 s/iter. ETA=0:06:22\n",
            "\u001b[32m[05/03 00:44:30 d2.evaluation.evaluator]: \u001b[0mInference done 2162/5823. Dataloading: 0.0016 s/iter. Inference: 0.1012 s/iter. Eval: 0.0003 s/iter. Total: 0.1033 s/iter. ETA=0:06:18\n",
            "\u001b[32m[05/03 00:44:35 d2.evaluation.evaluator]: \u001b[0mInference done 2211/5823. Dataloading: 0.0016 s/iter. Inference: 0.1012 s/iter. Eval: 0.0003 s/iter. Total: 0.1033 s/iter. ETA=0:06:12\n",
            "\u001b[32m[05/03 00:44:40 d2.evaluation.evaluator]: \u001b[0mInference done 2259/5823. Dataloading: 0.0016 s/iter. Inference: 0.1013 s/iter. Eval: 0.0003 s/iter. Total: 0.1033 s/iter. ETA=0:06:08\n",
            "\u001b[32m[05/03 00:44:45 d2.evaluation.evaluator]: \u001b[0mInference done 2307/5823. Dataloading: 0.0016 s/iter. Inference: 0.1013 s/iter. Eval: 0.0003 s/iter. Total: 0.1034 s/iter. ETA=0:06:03\n",
            "\u001b[32m[05/03 00:44:50 d2.evaluation.evaluator]: \u001b[0mInference done 2355/5823. Dataloading: 0.0016 s/iter. Inference: 0.1013 s/iter. Eval: 0.0003 s/iter. Total: 0.1034 s/iter. ETA=0:05:58\n",
            "\u001b[32m[05/03 00:44:55 d2.evaluation.evaluator]: \u001b[0mInference done 2403/5823. Dataloading: 0.0016 s/iter. Inference: 0.1014 s/iter. Eval: 0.0003 s/iter. Total: 0.1034 s/iter. ETA=0:05:53\n",
            "\u001b[32m[05/03 00:45:00 d2.evaluation.evaluator]: \u001b[0mInference done 2451/5823. Dataloading: 0.0016 s/iter. Inference: 0.1014 s/iter. Eval: 0.0003 s/iter. Total: 0.1035 s/iter. ETA=0:05:48\n",
            "\u001b[32m[05/03 00:45:05 d2.evaluation.evaluator]: \u001b[0mInference done 2499/5823. Dataloading: 0.0016 s/iter. Inference: 0.1015 s/iter. Eval: 0.0003 s/iter. Total: 0.1035 s/iter. ETA=0:05:44\n",
            "\u001b[32m[05/03 00:45:10 d2.evaluation.evaluator]: \u001b[0mInference done 2547/5823. Dataloading: 0.0016 s/iter. Inference: 0.1015 s/iter. Eval: 0.0003 s/iter. Total: 0.1035 s/iter. ETA=0:05:39\n",
            "\u001b[32m[05/03 00:45:15 d2.evaluation.evaluator]: \u001b[0mInference done 2594/5823. Dataloading: 0.0016 s/iter. Inference: 0.1015 s/iter. Eval: 0.0003 s/iter. Total: 0.1036 s/iter. ETA=0:05:34\n",
            "\u001b[32m[05/03 00:45:20 d2.evaluation.evaluator]: \u001b[0mInference done 2641/5823. Dataloading: 0.0016 s/iter. Inference: 0.1016 s/iter. Eval: 0.0003 s/iter. Total: 0.1036 s/iter. ETA=0:05:29\n",
            "\u001b[32m[05/03 00:45:25 d2.evaluation.evaluator]: \u001b[0mInference done 2689/5823. Dataloading: 0.0016 s/iter. Inference: 0.1016 s/iter. Eval: 0.0003 s/iter. Total: 0.1037 s/iter. ETA=0:05:24\n",
            "\u001b[32m[05/03 00:45:30 d2.evaluation.evaluator]: \u001b[0mInference done 2737/5823. Dataloading: 0.0016 s/iter. Inference: 0.1017 s/iter. Eval: 0.0003 s/iter. Total: 0.1037 s/iter. ETA=0:05:20\n",
            "\u001b[32m[05/03 00:45:35 d2.evaluation.evaluator]: \u001b[0mInference done 2785/5823. Dataloading: 0.0016 s/iter. Inference: 0.1017 s/iter. Eval: 0.0003 s/iter. Total: 0.1037 s/iter. ETA=0:05:15\n",
            "\u001b[32m[05/03 00:45:41 d2.evaluation.evaluator]: \u001b[0mInference done 2833/5823. Dataloading: 0.0016 s/iter. Inference: 0.1017 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:05:10\n",
            "\u001b[32m[05/03 00:45:46 d2.evaluation.evaluator]: \u001b[0mInference done 2880/5823. Dataloading: 0.0016 s/iter. Inference: 0.1018 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:05:05\n",
            "\u001b[32m[05/03 00:45:51 d2.evaluation.evaluator]: \u001b[0mInference done 2928/5823. Dataloading: 0.0016 s/iter. Inference: 0.1018 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:05:00\n",
            "\u001b[32m[05/03 00:45:56 d2.evaluation.evaluator]: \u001b[0mInference done 2975/5823. Dataloading: 0.0016 s/iter. Inference: 0.1018 s/iter. Eval: 0.0003 s/iter. Total: 0.1039 s/iter. ETA=0:04:55\n",
            "\u001b[32m[05/03 00:46:01 d2.evaluation.evaluator]: \u001b[0mInference done 3023/5823. Dataloading: 0.0016 s/iter. Inference: 0.1019 s/iter. Eval: 0.0003 s/iter. Total: 0.1039 s/iter. ETA=0:04:50\n",
            "\u001b[32m[05/03 00:46:06 d2.evaluation.evaluator]: \u001b[0mInference done 3071/5823. Dataloading: 0.0016 s/iter. Inference: 0.1019 s/iter. Eval: 0.0003 s/iter. Total: 0.1040 s/iter. ETA=0:04:46\n",
            "\u001b[32m[05/03 00:46:11 d2.evaluation.evaluator]: \u001b[0mInference done 3119/5823. Dataloading: 0.0017 s/iter. Inference: 0.1019 s/iter. Eval: 0.0003 s/iter. Total: 0.1040 s/iter. ETA=0:04:41\n",
            "\u001b[32m[05/03 00:46:16 d2.evaluation.evaluator]: \u001b[0mInference done 3167/5823. Dataloading: 0.0017 s/iter. Inference: 0.1020 s/iter. Eval: 0.0003 s/iter. Total: 0.1040 s/iter. ETA=0:04:36\n",
            "\u001b[32m[05/03 00:46:21 d2.evaluation.evaluator]: \u001b[0mInference done 3215/5823. Dataloading: 0.0017 s/iter. Inference: 0.1020 s/iter. Eval: 0.0003 s/iter. Total: 0.1041 s/iter. ETA=0:04:31\n",
            "\u001b[32m[05/03 00:46:26 d2.evaluation.evaluator]: \u001b[0mInference done 3263/5823. Dataloading: 0.0017 s/iter. Inference: 0.1020 s/iter. Eval: 0.0003 s/iter. Total: 0.1041 s/iter. ETA=0:04:26\n",
            "\u001b[32m[05/03 00:46:31 d2.evaluation.evaluator]: \u001b[0mInference done 3310/5823. Dataloading: 0.0017 s/iter. Inference: 0.1021 s/iter. Eval: 0.0003 s/iter. Total: 0.1041 s/iter. ETA=0:04:21\n",
            "\u001b[32m[05/03 00:46:36 d2.evaluation.evaluator]: \u001b[0mInference done 3358/5823. Dataloading: 0.0017 s/iter. Inference: 0.1021 s/iter. Eval: 0.0003 s/iter. Total: 0.1041 s/iter. ETA=0:04:16\n",
            "\u001b[32m[05/03 00:46:41 d2.evaluation.evaluator]: \u001b[0mInference done 3405/5823. Dataloading: 0.0017 s/iter. Inference: 0.1021 s/iter. Eval: 0.0003 s/iter. Total: 0.1042 s/iter. ETA=0:04:11\n",
            "\u001b[32m[05/03 00:46:46 d2.evaluation.evaluator]: \u001b[0mInference done 3454/5823. Dataloading: 0.0017 s/iter. Inference: 0.1021 s/iter. Eval: 0.0003 s/iter. Total: 0.1041 s/iter. ETA=0:04:06\n",
            "\u001b[32m[05/03 00:46:51 d2.evaluation.evaluator]: \u001b[0mInference done 3501/5823. Dataloading: 0.0017 s/iter. Inference: 0.1021 s/iter. Eval: 0.0003 s/iter. Total: 0.1042 s/iter. ETA=0:04:01\n",
            "\u001b[32m[05/03 00:46:56 d2.evaluation.evaluator]: \u001b[0mInference done 3550/5823. Dataloading: 0.0017 s/iter. Inference: 0.1021 s/iter. Eval: 0.0003 s/iter. Total: 0.1042 s/iter. ETA=0:03:56\n",
            "\u001b[32m[05/03 00:47:01 d2.evaluation.evaluator]: \u001b[0mInference done 3598/5823. Dataloading: 0.0017 s/iter. Inference: 0.1021 s/iter. Eval: 0.0003 s/iter. Total: 0.1042 s/iter. ETA=0:03:51\n",
            "\u001b[32m[05/03 00:47:06 d2.evaluation.evaluator]: \u001b[0mInference done 3646/5823. Dataloading: 0.0017 s/iter. Inference: 0.1021 s/iter. Eval: 0.0003 s/iter. Total: 0.1042 s/iter. ETA=0:03:46\n",
            "\u001b[32m[05/03 00:47:11 d2.evaluation.evaluator]: \u001b[0mInference done 3694/5823. Dataloading: 0.0017 s/iter. Inference: 0.1021 s/iter. Eval: 0.0003 s/iter. Total: 0.1042 s/iter. ETA=0:03:41\n",
            "\u001b[32m[05/03 00:47:16 d2.evaluation.evaluator]: \u001b[0mInference done 3742/5823. Dataloading: 0.0017 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1042 s/iter. ETA=0:03:36\n",
            "\u001b[32m[05/03 00:47:22 d2.evaluation.evaluator]: \u001b[0mInference done 3790/5823. Dataloading: 0.0017 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1042 s/iter. ETA=0:03:31\n",
            "\u001b[32m[05/03 00:47:27 d2.evaluation.evaluator]: \u001b[0mInference done 3839/5823. Dataloading: 0.0017 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1042 s/iter. ETA=0:03:26\n",
            "\u001b[32m[05/03 00:47:32 d2.evaluation.evaluator]: \u001b[0mInference done 3887/5823. Dataloading: 0.0017 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1042 s/iter. ETA=0:03:21\n",
            "\u001b[32m[05/03 00:47:37 d2.evaluation.evaluator]: \u001b[0mInference done 3935/5823. Dataloading: 0.0017 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1042 s/iter. ETA=0:03:16\n",
            "\u001b[32m[05/03 00:47:42 d2.evaluation.evaluator]: \u001b[0mInference done 3984/5823. Dataloading: 0.0017 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1042 s/iter. ETA=0:03:11\n",
            "\u001b[32m[05/03 00:47:47 d2.evaluation.evaluator]: \u001b[0mInference done 4032/5823. Dataloading: 0.0017 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1042 s/iter. ETA=0:03:06\n",
            "\u001b[32m[05/03 00:47:52 d2.evaluation.evaluator]: \u001b[0mInference done 4080/5823. Dataloading: 0.0017 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1043 s/iter. ETA=0:03:01\n",
            "\u001b[32m[05/03 00:47:57 d2.evaluation.evaluator]: \u001b[0mInference done 4127/5823. Dataloading: 0.0017 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1043 s/iter. ETA=0:02:56\n",
            "\u001b[32m[05/03 00:48:02 d2.evaluation.evaluator]: \u001b[0mInference done 4176/5823. Dataloading: 0.0017 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1043 s/iter. ETA=0:02:51\n",
            "\u001b[32m[05/03 00:48:07 d2.evaluation.evaluator]: \u001b[0mInference done 4224/5823. Dataloading: 0.0017 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1043 s/iter. ETA=0:02:46\n",
            "\u001b[32m[05/03 00:48:12 d2.evaluation.evaluator]: \u001b[0mInference done 4272/5823. Dataloading: 0.0017 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1043 s/iter. ETA=0:02:41\n",
            "\u001b[32m[05/03 00:48:17 d2.evaluation.evaluator]: \u001b[0mInference done 4321/5823. Dataloading: 0.0017 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1043 s/iter. ETA=0:02:36\n",
            "\u001b[32m[05/03 00:48:22 d2.evaluation.evaluator]: \u001b[0mInference done 4369/5823. Dataloading: 0.0017 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1043 s/iter. ETA=0:02:31\n",
            "\u001b[32m[05/03 00:48:27 d2.evaluation.evaluator]: \u001b[0mInference done 4418/5823. Dataloading: 0.0017 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1043 s/iter. ETA=0:02:26\n",
            "\u001b[32m[05/03 00:48:32 d2.evaluation.evaluator]: \u001b[0mInference done 4466/5823. Dataloading: 0.0017 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1043 s/iter. ETA=0:02:21\n",
            "\u001b[32m[05/03 00:48:37 d2.evaluation.evaluator]: \u001b[0mInference done 4513/5823. Dataloading: 0.0017 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1043 s/iter. ETA=0:02:16\n",
            "\u001b[32m[05/03 00:48:42 d2.evaluation.evaluator]: \u001b[0mInference done 4561/5823. Dataloading: 0.0017 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1043 s/iter. ETA=0:02:11\n",
            "\u001b[32m[05/03 00:48:47 d2.evaluation.evaluator]: \u001b[0mInference done 4609/5823. Dataloading: 0.0017 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1043 s/iter. ETA=0:02:06\n",
            "\u001b[32m[05/03 00:48:53 d2.evaluation.evaluator]: \u001b[0mInference done 4656/5823. Dataloading: 0.0017 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1044 s/iter. ETA=0:02:01\n",
            "\u001b[32m[05/03 00:48:58 d2.evaluation.evaluator]: \u001b[0mInference done 4704/5823. Dataloading: 0.0017 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1044 s/iter. ETA=0:01:56\n",
            "\u001b[32m[05/03 00:49:03 d2.evaluation.evaluator]: \u001b[0mInference done 4752/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1044 s/iter. ETA=0:01:51\n",
            "\u001b[32m[05/03 00:49:08 d2.evaluation.evaluator]: \u001b[0mInference done 4800/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1044 s/iter. ETA=0:01:46\n",
            "\u001b[32m[05/03 00:49:13 d2.evaluation.evaluator]: \u001b[0mInference done 4848/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1044 s/iter. ETA=0:01:41\n",
            "\u001b[32m[05/03 00:49:18 d2.evaluation.evaluator]: \u001b[0mInference done 4897/5823. Dataloading: 0.0017 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1044 s/iter. ETA=0:01:36\n",
            "\u001b[32m[05/03 00:49:23 d2.evaluation.evaluator]: \u001b[0mInference done 4944/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1044 s/iter. ETA=0:01:31\n",
            "\u001b[32m[05/03 00:49:28 d2.evaluation.evaluator]: \u001b[0mInference done 4993/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1044 s/iter. ETA=0:01:26\n",
            "\u001b[32m[05/03 00:49:33 d2.evaluation.evaluator]: \u001b[0mInference done 5041/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1044 s/iter. ETA=0:01:21\n",
            "\u001b[32m[05/03 00:49:38 d2.evaluation.evaluator]: \u001b[0mInference done 5089/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1044 s/iter. ETA=0:01:16\n",
            "\u001b[32m[05/03 00:49:43 d2.evaluation.evaluator]: \u001b[0mInference done 5137/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1044 s/iter. ETA=0:01:11\n",
            "\u001b[32m[05/03 00:49:48 d2.evaluation.evaluator]: \u001b[0mInference done 5185/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1044 s/iter. ETA=0:01:06\n",
            "\u001b[32m[05/03 00:49:53 d2.evaluation.evaluator]: \u001b[0mInference done 5233/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1045 s/iter. ETA=0:01:01\n",
            "\u001b[32m[05/03 00:49:58 d2.evaluation.evaluator]: \u001b[0mInference done 5281/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1045 s/iter. ETA=0:00:56\n",
            "\u001b[32m[05/03 00:50:03 d2.evaluation.evaluator]: \u001b[0mInference done 5329/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1045 s/iter. ETA=0:00:51\n",
            "\u001b[32m[05/03 00:50:08 d2.evaluation.evaluator]: \u001b[0mInference done 5377/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1045 s/iter. ETA=0:00:46\n",
            "\u001b[32m[05/03 00:50:13 d2.evaluation.evaluator]: \u001b[0mInference done 5425/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1045 s/iter. ETA=0:00:41\n",
            "\u001b[32m[05/03 00:50:18 d2.evaluation.evaluator]: \u001b[0mInference done 5473/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1045 s/iter. ETA=0:00:36\n",
            "\u001b[32m[05/03 00:50:23 d2.evaluation.evaluator]: \u001b[0mInference done 5522/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1045 s/iter. ETA=0:00:31\n",
            "\u001b[32m[05/03 00:50:28 d2.evaluation.evaluator]: \u001b[0mInference done 5571/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1045 s/iter. ETA=0:00:26\n",
            "\u001b[32m[05/03 00:50:34 d2.evaluation.evaluator]: \u001b[0mInference done 5619/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1045 s/iter. ETA=0:00:21\n",
            "\u001b[32m[05/03 00:50:39 d2.evaluation.evaluator]: \u001b[0mInference done 5667/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1045 s/iter. ETA=0:00:16\n",
            "\u001b[32m[05/03 00:50:44 d2.evaluation.evaluator]: \u001b[0mInference done 5716/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1045 s/iter. ETA=0:00:11\n",
            "\u001b[32m[05/03 00:50:49 d2.evaluation.evaluator]: \u001b[0mInference done 5765/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1045 s/iter. ETA=0:00:06\n",
            "\u001b[32m[05/03 00:50:54 d2.evaluation.evaluator]: \u001b[0mInference done 5813/5823. Dataloading: 0.0017 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1045 s/iter. ETA=0:00:01\n",
            "\u001b[32m[05/03 00:50:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:10:07.724757 (0.104456 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/03 00:50:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:09:55 (0.102395 s / iter per device, on 1 devices)\n",
            "\u001b[32m[05/03 00:50:55 d2.evaluation.pascal_voc_evaluation]: \u001b[0mEvaluating voc_val using 2012 metric. Note that results do not use the official Matlab API.\n",
            "\u001b[32m[05/03 00:51:36 d2.engine.defaults]: \u001b[0mEvaluation results for voc_val in csv format:\n",
            "\u001b[32m[05/03 00:51:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/03 00:51:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75\n",
            "\u001b[32m[05/03 00:51:36 d2.evaluation.testing]: \u001b[0mcopypaste: 22.3152,53.6966,12.5697\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_folder = \"./output\"\n",
        "\n",
        "for root, _, files in os.walk(output_folder):\n",
        "    for fname in files:\n",
        "        file_path = os.path.join(root, fname)\n",
        "        artifact_name = os.path.relpath(file_path, output_folder)\n",
        "        task.upload_artifact(name=artifact_name, artifact_object=file_path)\n",
        "        print(f\"Uploaded {artifact_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "task.close()"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
